{"assignees":[],"author":{"id":"MDQ6VXNlcjUyMjA1","is_bot":false,"login":"dandavison","name":"Dan Davison"},"body":"## Expected Behavior\r\nCompleteUpdate command should be honored when submitted in the same workflow task completion as ContinueAsNew.\r\n\r\n## Actual Behavior\r\n\r\nOccasionally, there is a server error and it is not honored, and the update is applied to the post-ContinueAsNew run.\r\n\r\nI have a workflow that CANs in the same WFT as an update is completed.\r\nI ensure that the update is sent in the first WFT and, most of the time, I see what I expect:\r\n\r\n1. worker receives WFT: `[doUpdate, startWorkflow]`\r\n2. worker sends WFT completion: `[accept&completeUpdate, CAN]`\r\n3. update caller gets successful update response\r\n4. worker receives WFT after CAN: `[startWorkflow]`\r\n5. workflow completes\r\n\r\nHowever, sometimes (~1/20) I see\r\n\r\n1. \\<as above\\>\r\n2. \\<as above>\r\n3. server error when handling UpdateWorkflowExecution: [`unable to locate current workflow execution`](https://github.com/temporalio/temporal/blob/99f15c4dabf9a22763aaa13653c83a832bd0fffa/service/history/statemachine_environment.go#L167) (update caller does not get a response)\r\n4. WFT after CAN contains the update for a second time, in addition to startWorkflow\r\n\r\nI assume what's happening is that the server error causes an internal retry (FE => History) of the UpdateWorkflowExecution, and this retry lands on the 2nd run, after CAN. But I haven't yet dug into why the server error happens\r\n```\r\n\t// for close workflow we need to check if it is still the current run\r\n\t// since it's possible that the workflowID has a newer run before it's locked \r\n\r\nwcache.GetCurrentRunID(...) != wfContext.GetWorkflowKey().RunID\r\n```\r\n\r\n\r\n## Steps to Reproduce the Problem\r\n\r\nThis was discovered while writing tests for `sdk-typescript`. In lieu of a simpler repro, it can be repro'd as follows\r\n\r\n<details>\r\n<summary>steps to repro</summary>\r\n\r\n```\r\ngit clone git@github.com:temporalio/sdk-typescript.git\r\ncd sdk-typescript\r\ngit fetch origin  1459-server-error-repro\r\ngit checkout 1459-server-error-repro\r\ngit submodule update --init --recursive\r\n\r\n# Build temporal CLI against server 99f15c4dabf9a22763aaa13653c83a832bd0fffa\r\n# Look at last commit, modify to use path to your temporal CLI executable\r\n\r\nrustup update\r\nnpm install\r\nnpm run build\r\nfor i in `seq 1 100`; do (cd packages/test && npm run test -- -m 'unfinished update handler with continue-as-new waiting for all handlers to finish') || break; done\r\n```\r\n</details>\r\n\r\n\r\n\r\n\r\n\r\n<details>\r\n<summary>Log in happy case</summary>\r\n\r\n```\r\n[runUnfinishedHandlersWorkflowTerminationTypeWorkflow(a12a0761-d96e-4111-973b-1e54027baaed)] ðŸŸ  job: doUpdate {\"doUpdate\":{\"id\":\"update-id\",\"protocolInstanceId\":\"update-id\",\"name\":\"unfinishedHandlersWorkflowTermina\r\ntionTypeUpdate\",\"meta\":{\"updateId\":\"update-id\",\"identity\":\"57045@dan-2.local\"},\"runValidator\":true}}\r\n[runUnfinishedHandlersWorkflowTerminationTypeWorkflow(a12a0761-d96e-4111-973b-1e54027baaed)] ðŸŸ  job: startWorkflow {\"startWorkflow\":{\"workflowType\":\"runUnfinishedHandlersWorkflowTerminationTypeWorkflow\",\"workflowId\r\n\":\"a12a0761-d96e-4111-973b-1e54027baaed\",\"arguments\":[{\"metadata\":{\"encoding\":\"anNvbi9wbGFpbg==\"},\"data\":\"ImNvbnRpbnVlLWFzLW5ldyI=\"},{\"metadata\":{\"encoding\":\"anNvbi9wbGFpbg==\"},\"data\":\"IndhaXQtYWxsLWhhbmRsZXJzLWZpb\r\nmlzaGVkIg==\"}],\"randomnessSeed\":\"3270138216709017763\",\"identity\":\"57045@dan-2.local\",\"workflowTaskTimeout\":{\"seconds\":\"10\"},\"lastCompletionResult\":{},\"firstExecutionRunId\":\"8a25effa-1499-46b6-be24-0a3d23c1fb66\",\"at\r\ntempt\":1,\"cronScheduleToScheduleInterval\":{},\"memo\":{},\"startTime\":{\"seconds\":\"1722604980\",\"nanos\":463150000}}}\r\n[runUnfinishedHandlersWorkflowTerminationTypeWorkflow(a12a0761-d96e-4111-973b-1e54027baaed)] ðŸŸ¢ activationCompletion: [{\"updateResponse\":{\"protocolInstanceId\":\"update-id\",\"accepted\":{}}},{\"updateResponse\":{\"protoco\r\nlInstanceId\":\"update-id\",\"completed\":{\"metadata\":{\"encoding\":{\"0\":106,\"1\":115,\"2\":111,\"3\":110,\"4\":47,\"5\":112,\"6\":108,\"7\":97,\"8\":105,\"9\":110}},\"data\":{\"0\":34,\"1\":117,\"2\":112,\"3\":100,\"4\":97,\"5\":116,\"6\":101,\"7\":45,\"8\"\r\n:114,\"9\":101,\"10\":115,\"11\":117,\"12\":108,\"13\":116,\"14\":34}}}},{\"continueAsNewWorkflowExecution\":{\"workflowType\":\"runUnfinishedHandlersWorkflowTerminationTypeWorkflow\",\"arguments\":[{\"metadata\":{\"encoding\":{\"0\":106,\"1\r\n\":115,\"2\":111,\"3\":110,\"4\":47,\"5\":112,\"6\":108,\"7\":97,\"8\":105,\"9\":110}},\"data\":{\"0\":34,\"1\":114,\"2\":101,\"3\":116,\"4\":117,\"5\":114,\"6\":110,\"7\":34}}],\"headers\":{},\"taskQueue\":\"unfinished_update_handler_with_continue-as-ne\r\nw_waiting_for_all_handlers_to_finish\",\"versioningIntent\":0}}]\r\nâœ… caller got update result\r\n[runUnfinishedHandlersWorkflowTerminationTypeWorkflow(a12a0761-d96e-4111-973b-1e54027baaed)] ðŸŸ  job: startWorkflow {\"startWorkflow\":{\"workflowType\":\"runUnfinishedHandlersWorkflowTerminationTypeWorkflow\",\"workflowId\r\n\":\"a12a0761-d96e-4111-973b-1e54027baaed\",\"arguments\":[{\"metadata\":{\"encoding\":\"anNvbi9wbGFpbg==\"},\"data\":\"InJldHVybiI=\"}],\"randomnessSeed\":\"17192061066528283883\",\"workflowRunTimeout\":{},\"workflowTaskTimeout\":{\"seco\r\nnds\":\"10\"},\"continuedFromExecutionRunId\":\"8a25effa-1499-46b6-be24-0a3d23c1fb66\",\"continuedInitiator\":\"CONTINUE_AS_NEW_INITIATOR_WORKFLOW\",\"lastCompletionResult\":{},\"firstExecutionRunId\":\"8a25effa-1499-46b6-be24-0a3\r\nd23c1fb66\",\"attempt\":1,\"cronScheduleToScheduleInterval\":{\"nanos\":501851000},\"memo\":{},\"startTime\":{\"seconds\":\"1722604980\",\"nanos\":938805000}}}\r\n[runUnfinishedHandlersWorkflowTerminationTypeWorkflow(a12a0761-d96e-4111-973b-1e54027baaed)] ðŸŸ¢ activationCompletion: [{\"completeWorkflowExecution\":{\"result\":{\"metadata\":{\"encoding\":{\"0\":98,\"1\":105,\"2\":110,\"3\":97,\"\r\n4\":114,\"5\":121,\"6\":47,\"7\":110,\"8\":117,\"9\":108,\"10\":108}}}}}]\r\n```\r\n\r\n</details>\r\n\r\n\r\n<details>\r\n<summary>Log in unhappy case</summary>\r\n\r\n```\r\n[runUnfinishedHandlersWorkflowTerminationTypeWorkflow(f1f37cd3-1c11-4aa7-ba58-f12f8880f594)] ðŸŸ  job: doUpdate {\"doUpdate\":{\"id\":\"update-id\",\"protocolInstanceId\":\"update-id\",\"name\":\"unfinishedHandlersWorkflowTermina\r\ntionTypeUpdate\",\"meta\":{\"updateId\":\"update-id\",\"identity\":\"57075@dan-2.local\"},\"runValidator\":true}}\r\n[runUnfinishedHandlersWorkflowTerminationTypeWorkflow(f1f37cd3-1c11-4aa7-ba58-f12f8880f594)] ðŸŸ  job: startWorkflow {\"startWorkflow\":{\"workflowType\":\"runUnfinishedHandlersWorkflowTerminationTypeWorkflow\",\"workflowId\r\n\":\"f1f37cd3-1c11-4aa7-ba58-f12f8880f594\",\"arguments\":[{\"metadata\":{\"encoding\":\"anNvbi9wbGFpbg==\"},\"data\":\"ImNvbnRpbnVlLWFzLW5ldyI=\"},{\"metadata\":{\"encoding\":\"anNvbi9wbGFpbg==\"},\"data\":\"IndhaXQtYWxsLWhhbmRsZXJzLWZpb\r\nmlzaGVkIg==\"}],\"randomnessSeed\":\"3129644504916450612\",\"identity\":\"57075@dan-2.local\",\"workflowTaskTimeout\":{\"seconds\":\"10\"},\"lastCompletionResult\":{},\"firstExecutionRunId\":\"d47f00b8-1462-4a45-821d-5e72c853f631\",\"at\r\ntempt\":1,\"cronScheduleToScheduleInterval\":{},\"memo\":{},\"startTime\":{\"seconds\":\"1722604985\",\"nanos\":101629000}}}\r\n[runUnfinishedHandlersWorkflowTerminationTypeWorkflow(f1f37cd3-1c11-4aa7-ba58-f12f8880f594)] ðŸŸ¢ activationCompletion: [{\"updateResponse\":{\"protocolInstanceId\":\"update-id\",\"accepted\":{}}},{\"updateResponse\":{\"protoco\r\nlInstanceId\":\"update-id\",\"completed\":{\"metadata\":{\"encoding\":{\"0\":106,\"1\":115,\"2\":111,\"3\":110,\"4\":47,\"5\":112,\"6\":108,\"7\":97,\"8\":105,\"9\":110}},\"data\":{\"0\":34,\"1\":117,\"2\":112,\"3\":100,\"4\":97,\"5\":116,\"6\":101,\"7\":45,\"8\"\r\n:114,\"9\":101,\"10\":115,\"11\":117,\"12\":108,\"13\":116,\"14\":34}}}},{\"continueAsNewWorkflowExecution\":{\"workflowType\":\"runUnfinishedHandlersWorkflowTerminationTypeWorkflow\",\"arguments\":[{\"metadata\":{\"encoding\":{\"0\":106,\"1\r\n\":115,\"2\":111,\"3\":110,\"4\":47,\"5\":112,\"6\":108,\"7\":97,\"8\":105,\"9\":110}},\"data\":{\"0\":34,\"1\":114,\"2\":101,\"3\":116,\"4\":117,\"5\":114,\"6\":110,\"7\":34}}],\"headers\":{},\"taskQueue\":\"unfinished_update_handler_with_continue-as-ne\r\nw_waiting_for_all_handlers_to_finish\",\"versioningIntent\":0}}]\r\ntime=2024-08-02T09:23:05.598 level=ERROR msg=\"service failures\" operation=UpdateWorkflowExecution wf-namespace=default error=\"unable to locate current workflow execution\"\r\n[runUnfinishedHandlersWorkflowTerminationTypeWorkflow(f1f37cd3-1c11-4aa7-ba58-f12f8880f594)] ðŸŸ  job: doUpdate {\"doUpdate\":{\"id\":\"update-id\",\"protocolInstanceId\":\"update-id\",\"name\":\"unfinishedHandlersWorkflowTermina\r\ntionTypeUpdate\",\"meta\":{\"updateId\":\"update-id\",\"identity\":\"57075@dan-2.local\"},\"runValidator\":true}}\r\n[runUnfinishedHandlersWorkflowTerminationTypeWorkflow(f1f37cd3-1c11-4aa7-ba58-f12f8880f594)] ðŸŸ  job: startWorkflow {\"startWorkflow\":{\"workflowType\":\"runUnfinishedHandlersWorkflowTerminationTypeWorkflow\",\"workflowId\r\n\":\"f1f37cd3-1c11-4aa7-ba58-f12f8880f594\",\"arguments\":[{\"metadata\":{\"encoding\":\"anNvbi9wbGFpbg==\"},\"data\":\"InJldHVybiI=\"}],\"randomnessSeed\":\"17700601131409760754\",\"workflowRunTimeout\":{},\"workflowTaskTimeout\":{\"seco\r\nnds\":\"10\"},\"continuedFromExecutionRunId\":\"d47f00b8-1462-4a45-821d-5e72c853f631\",\"continuedInitiator\":\"CONTINUE_AS_NEW_INITIATOR_WORKFLOW\",\"lastCompletionResult\":{},\"firstExecutionRunId\":\"d47f00b8-1462-4a45-821d-5e7\r\n2c853f631\",\"attempt\":1,\"cronScheduleToScheduleInterval\":{\"nanos\":566360000},\"memo\":{},\"startTime\":{\"seconds\":\"1722604985\",\"nanos\":513977000}}}\r\n[runUnfinishedHandlersWorkflowTerminationTypeWorkflow(f1f37cd3-1c11-4aa7-ba58-f12f8880f594)] ðŸŸ¢ activationCompletion: [{\"updateResponse\":{\"protocolInstanceId\":\"update-id\",\"accepted\":{}}},{\"completeWorkflowExecution\r\n\":{\"result\":{\"metadata\":{\"encoding\":{\"0\":98,\"1\":105,\"2\":110,\"3\":97,\"4\":114,\"5\":121,\"6\":47,\"7\":110,\"8\":117,\"9\":108,\"10\":108}}}}}]\r\n```\r\n\r\n</details>\r\n\r\n\r\n\r\n## Specifications\r\n\r\n  - Version: Server built from latest `main` 99f15c4dabf9a22763aaa13653c83a832bd0fffa\r\n","closedAt":null,"comments":[{"id":"IC_kwDODNqesM6HuYfI","author":{"login":"dandavison"},"authorAssociation":"MEMBER","body":"It seems that there are a total of 3 `UpdateWorkflowRequests` made to History service.\r\n\r\n- The first request is delivered to the worker, but is ultimately failed as it is completing, and is retried by the Frontend service.\r\n- The second fails immediately on entry to History service and is retried by the Frontend service.\r\n- The final request lands on the post-CAN run and thus is treated as a distinct update (executed a second time by a worker).\r\n\r\n```\r\nUpdateWorkflowExecution\r\nnamespace_id:\"98d00113-d1ae-4623-8b71-f24f5aac51cd\"  request:{namespace:\"default\"  workflow_execution:{workflow_id:\"f95ace75-8b2e-4c78-933c-8b813e4c7b48\"}  first_execution_run_id:\"d0442481-44d1-451b-9f14-50ad7d63b2bb\"  wait_policy:{lifecycle_stage:UPDATE_WORKFLOW_EXECUTION_LIFECYCLE_STAGE_COMPLETED}  request:{meta:{update_id:\"update-id\"  identity:\"66459@dan-2.local\"}  input:{header:{}  name:\"unfinishedHandlersWorkflowTerminationTypeUpdate\"  args:{}}}}\r\n<nil>, Workflow Update was aborted.\r\n\r\nUpdateWorkflowExecution\r\nnamespace_id:\"98d00113-d1ae-4623-8b71-f24f5aac51cd\"  request:{namespace:\"default\"  workflow_execution:{workflow_id:\"f95ace75-8b2e-4c78-933c-8b813e4c7b48\"}  first_execution_run_id:\"d0442481-44d1-451b-9f14-50ad7d63b2bb\"  wait_policy:{lifecycle_stage:UPDATE_WORKFLOW_EXECUTION_LIFECYCLE_STAGE_COMPLETED}  request:{meta:{update_id:\"update-id\"  identity:\"66459@dan-2.local\"}  input:{header:{}  name:\"unfinishedHandlersWorkflowTerminationTypeUpdate\"  args:{}}}}\r\n<nil>, unable to locate current workflow execution\r\n\r\nUpdateWorkflowExecution\r\nnamespace_id:\"98d00113-d1ae-4623-8b71-f24f5aac51cd\"  request:{namespace:\"default\"  workflow_execution:{workflow_id:\"f95ace75-8b2e-4c78-933c-8b813e4c7b48\"}  first_execution_run_id:\"d0442481-44d1-451b-9f14-50ad7d63b2bb\"  wait_policy:{lifecycle_stage:UPDATE_WORKFLOW_EXECUTION_LIFECYCLE_STAGE_COMPLETED}  request:{meta:{update_id:\"update-id\"  identity:\"66459@dan-2.local\"}  input:{header:{}  name:\"unfinishedHandlersWorkflowTerminationTypeUpdate\"  args:{}}}}\r\n<nil>, workflow execution already completed <-- this happens because of the nature of the Typescript test being used.\r\n```","createdAt":"2024-08-09T03:42:43Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/6375#issuecomment-2277083080","viewerDidAuthor":false},{"id":"IC_kwDODNqesM6Hzh6-","author":{"login":"mfateev"},"authorAssociation":"MEMBER","body":"Wouldn't the same happen with a signal?","createdAt":"2024-08-09T17:42:11Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/6375#issuecomment-2278432446","viewerDidAuthor":true},{"id":"IC_kwDODNqesM6IEv75","author":{"login":"alexshtin"},"authorAssociation":"CONTRIBUTOR","body":"It is kinda similar observable effect but probability to face it in real life are different, and I have hard times to understand which one is more likely.\r\n\r\nSignals can be delivered twice when event was successfully written into the history by history service, **and** then it crashed w/o replying to frontend, or frontend service lost connection to history service, and workflow, while receiving and processing this signal replies with CAN, and then frontend, or API caller retries and 2nd attempt lands on 2nd run. Something really bad should happen on the server to trigger it.\r\n\r\nUpdates are different in a sense that **any** error with workflow (in the @dandavison's case it was matching tried to start workflow task 2nd time) leads to lost update, and trigger frontend retry. Retries for updates are part of design: server relies on retries to recreate update after those errors. This sounds like much more likely to happen. With one caveat though: updates are mostly delivered with speculative workflow task, and this task is also lost with any error. It means that server wouldn't process update acceptance for the 1st run. Update can go on normal workflow task only if it piggybacks existing workflow task created by something else (this is exactly what happened in @dandavison`s case where update was delivered on first workflow task). This fact, seems to me, significantly reduce chances of facing this issue in real life.","createdAt":"2024-08-12T00:23:44Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/6375#issuecomment-2282946297","viewerDidAuthor":false}],"createdAt":"2024-08-06T16:25:17Z","labels":[{"id":"MDU6TGFiZWwyMDE5ODE3MzQ2","name":"potential-bug","description":"","color":"66b9cc"}],"milestone":null,"number":6375,"reactionGroups":[],"state":"OPEN","title":"CompleteUpdate message is sometimes not honored when in same WFT completion as ContinueAsNew","updatedAt":"2024-08-12T00:23:46Z","url":"https://github.com/temporalio/temporal/issues/6375"}
