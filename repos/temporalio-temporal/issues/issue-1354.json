{"assignees":[{"id":"MDQ6VXNlcjg3NjI4OTM=","login":"wxing1292","name":"Wenquan Xing","databaseId":0}],"author":{"id":"MDQ6VXNlcjEwODc0MQ==","is_bot":false,"login":"robzienert","name":"Rob Zienert"},"body":"## Expected Behavior\r\n\r\nI would expect a newly provisioned XDC temporal deployment with 2 clusters, and no connected workers, to have a relatively low `persistence_requests(OperationType=GetReplicationTasks)` metric.\r\n\r\n## Actual Behavior\r\n\r\nI have two new Temporal clusters, named `uswest2` and `useast1` which I've setup with a global namespace. Both of the clusters are connecting to their own MySQL and ElasticSearch clusters. We've configured for 16k shards.\r\n\r\n```\r\nName: default\r\nId: 9afe4304-74fb-4a8d-ad74-51497fae3b08\r\nDescription: Default Spinnaker namespace\r\nOwnerEmail: OMITTED\r\nNamespaceData: map[string]string(nil)\r\nState: Registered\r\nRetentionInDays: 672h0m0s\r\nActiveClusterName: useast1\r\nClusters: uswest2, useast1\r\nHistoryArchivalState: Disabled\r\nVisibilityArchivalState: Disabled\r\nBad binaries to reset:\r\n+-----------------+----------+------------+--------+\r\n| BINARY CHECKSUM | OPERATOR | START TIME | REASON |\r\n+-----------------+----------+------------+--------+\r\n+-----------------+----------+------------+--------+\r\n```\r\n\r\nWithout any workers connected, we're seeing a very high `persistence_requests(OperationType=GetReplicationTasks)` from the `history` service:\r\n\r\n![history-staging](https://user-images.githubusercontent.com/108741/110017807-7787c280-7cdb-11eb-9dab-b50f7059955b.png)\r\n\r\nThe service logs are unremarkable - no activity, no errors. I can communicate with the frontend API perfectly fine.\r\n\r\n## Specifications\r\n\r\n  - Version: 1.7.0\r\n  - Platform: Linux?\r\n","closedAt":"2021-03-27T04:04:26Z","comments":[{"id":"MDEyOklzc3VlQ29tbWVudDc5MDg3MjYzMA==","author":{"login":"robzienert"},"authorAssociation":"CONTRIBUTOR","body":"Happy to add any other graphs or anything that might help diagnose what's going on. Or maybe this is correct, and XDC replication is just has a _really high_ QPS baseline?","createdAt":"2021-03-04T19:31:15Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/1354#issuecomment-790872630","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDc5MDg3Njg0OA==","author":{"login":"wxing1292"},"authorAssociation":"CONTRIBUTOR","body":"> Happy to add any other graphs or anything that might help diagnose what's going on. Or maybe this is correct, and XDC replication is just has a _really high_ QPS baseline?\r\n\r\nyes and no, there should be some optimization which eliminates some unnecessary DB calls","createdAt":"2021-03-04T19:37:43Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/1354#issuecomment-790876848","viewerDidAuthor":false},{"id":"MDEyOklzc3VlQ29tbWVudDc5MDk3MTgzMA==","author":{"login":"robzienert"},"authorAssociation":"CONTRIBUTOR","body":"> yes and no, there should be some optimization which eliminates some unnecessary DB calls\r\n\r\nSo, generally speaking, a baseline of 5,000 QPS for 16k history shards seems reasonable to you?","createdAt":"2021-03-04T21:53:20Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/1354#issuecomment-790971830","viewerDidAuthor":false}],"createdAt":"2021-03-04T19:30:18Z","labels":[{"id":"MDU6TGFiZWwyMDE5ODE3MzQ2","name":"potential-bug","description":"","color":"66b9cc"}],"milestone":null,"number":1354,"reactionGroups":[],"state":"CLOSED","title":"High GetReplicationTasks QPS on clusters without any connected clients","updatedAt":"2021-03-27T04:04:26Z","url":"https://github.com/temporalio/temporal/issues/1354"}
