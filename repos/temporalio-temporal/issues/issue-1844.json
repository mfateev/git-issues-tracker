{"assignees":[{"id":"MDQ6VXNlcjQ2NjcyMw==","login":"dnr","name":"David Reiss","databaseId":0},{"id":"MDQ6VXNlcjU5NDI5NjM=","login":"MichaelSnowden","name":"Michael Snowden","databaseId":0}],"author":{"id":"MDQ6VXNlcjM3MjE0MQ==","is_bot":false,"login":"skrul","name":"Steve Krulewitz"},"body":"## Expected Behavior\r\n\r\nTaskqueue scavenger should run without emitting an excessive amount of persistence error metrics and not cause a dip in persistence availability.\r\n\r\n## Actual Behavior\r\n\r\nEvery time the taskqueue scavenger runs, it emits quite a few `persistence_errors` metrics with operations `gettasks`, `deletetaskqueue`, `listtaskqueue` and `completetaskslessthan`, enough to affect a dip in our persistence availability metric (persistence_errors vs. persistence_requests).\r\n\r\nThe scavenger does appear to be making progress and successfully deleting queues, so it is unclear what all these errors are about. Unfortunately the code does not log error messages.\r\n\r\nAre these errors expected? Should I be excluding worker persistence metrics from my overall persistence availability metric?\r\n\r\n## Specifications\r\n\r\n  - Version: 1.8\r\n  - Platform:\r\n","closedAt":null,"comments":[{"id":"IC_kwDODNqesM415X-R","author":{"login":"yiminc"},"authorAssociation":"MEMBER","body":"@skrul , could you paste a few example of the error logs emitted? \r\n== update ==\r\nOk, now I see that you mention there is no error logs. Could you paste the metrics query that you use to associate the issue with taskqueue scavenger.","createdAt":"2021-08-24T00:47:44Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/1844#issuecomment-904232849","viewerDidAuthor":false},{"id":"IC_kwDODNqesM415jCi","author":{"login":"skrul"},"authorAssociation":"NONE","body":"The query is something like:\r\n\r\n```\r\nsum:temporal_server.persistence_errors{app:temporal-worker-myapp-production} by {operation,app}.as_count()\r\n```\r\n\r\nIn our case the app tag has the role of the server so in this case I know that it is coming from a worker. This was during a run that deleted ~5k taskqueues:\r\n\r\n![image](https://user-images.githubusercontent.com/372141/130546970-7757c406-9026-4ee8-9ea1-731f189178a3.png)\r\n\r\nDuring this time the database wasn't under any particularly high load but it did get hit pretty hard with reads:\r\n\r\n![image](https://user-images.githubusercontent.com/372141/130547473-9c4809ba-bf61-46cf-a2a4-9b97c32dbea2.png)\r\n\r\nAnd a bunch of new connections:\r\n\r\n![image](https://user-images.githubusercontent.com/372141/130547536-23ce519f-b810-4899-8df1-cb435beb22e4.png)\r\n\r\nNow I'm thinking this could be due to the fact that we don't have a max connection pool set on the worker.\r\n","createdAt":"2021-08-24T02:45:54Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/1844#issuecomment-904278178","viewerDidAuthor":false},{"id":"IC_kwDODNqesM418M4L","author":{"login":"yiminc"},"authorAssociation":"MEMBER","body":"@skrul how do you get to know that run deleted 5K task queues? Do you know how many tasks were there in those queues? Because inorder to delete a queue, the scavenger need to make sure all tasks in the queue are expired. If those queue has lots of tasks in them and no one is polling from those tasks, it would cause the scavenger to read through all of them before it can be deleted. \r\n\r\nThere are a few metrics we can read to better understand the situation:\r\nhttps://github.com/temporalio/temporal/blob/fe05751305b1cb50b68efa23f8aa5f1b34f45bc5/service/worker/scanner/taskqueue/scavenger.go#L186\r\nhttps://github.com/temporalio/temporal/blob/fe05751305b1cb50b68efa23f8aa5f1b34f45bc5/service/worker/scanner/taskqueue/scavenger.go#L194-L197\r\n\r\nAlso, the task queue scavenger is a cron workflow that runs every 12 hours. It has only one activity that would spin up 32 executor concurrently each to scan through one task queue.","createdAt":"2021-08-24T21:05:33Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/1844#issuecomment-904973835","viewerDidAuthor":false},{"id":"IC_kwDODNqesM447bwh","author":{"login":"aliceabe"},"authorAssociation":"NONE","body":"Just wanted to update this thread with our latest findings. We know the run deletes about 5k task queues by looking at the log lines \"taskqueue deleted\". Unfortunately the job doesn't log when it encounters persistence errors, it just infinitely retries. Ideally, we should make this job more configurable, for example allow users to configure the task queue batch size:\r\n\r\nhttps://github.com/temporalio/temporal/blob/fe05751305b1cb50b68efa23f8aa5f1b34f45bc5/service/worker/scanner/taskqueue/scavenger.go#L79\r\n\r\nOr at least pass and use the max persistence QPS setting in the task queue scavenger, similar to how it's used in the history scavenger:\r\n\r\nhttps://github.com/temporalio/temporal/blob/fe05751305b1cb50b68efa23f8aa5f1b34f45bc5/service/worker/scanner/history/scavenger.go#L116-L118","createdAt":"2021-10-29T23:49:28Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/1844#issuecomment-955104289","viewerDidAuthor":false}],"createdAt":"2021-08-23T20:30:11Z","labels":[{"id":"MDU6TGFiZWwyMDE5ODE3MzQ2","name":"potential-bug","description":"","color":"66b9cc"}],"milestone":null,"number":1844,"reactionGroups":[],"state":"OPEN","title":"Taskqueue scavenger emits persistence errors","updatedAt":"2023-03-03T20:21:35Z","url":"https://github.com/temporalio/temporal/issues/1844"}
