{"assignees":[],"author":{"id":"MDQ6VXNlcjM2OTg2Mw==","is_bot":false,"login":"gnarea","name":"Gus Narea"},"body":"## Expected Behavior\n\nWorkflow deletion batch jobs should successfully delete all workflows matching the specified query when they report completion.\n\n## Actual Behavior\n\nBatch delete operations report successful completion but fail to actually delete the target workflows, regardless of batch size. This affects both large-scale operations (500k+ workflows) and small batches (56 workflows).\n\nChecking the logs, I found two groups of errors:\n\n- \"Operation failed with an error\" logs with `context deadline exceeded` in visibility deletion. Example:\n  ```json\n  {\n    \"stacktrace\": \"go.temporal.io/server/common/log.(*zapLogger).Error\n      /home/runner/work/docker-builds/docker-builds/temporal/common/log/zap_logger.go:154\n      go.temporal.io/server/common/persistence/visibility.(*visibilityManagerMetrics).updateErrorMetric\n      /home/runner/work/docker-builds/docker-builds/temporal/common/persistence/visibility/visiblity_manager_metrics.go:217\n    go.temporal.io/server/common/persistence/visibility.(*visibilityManagerMetrics).DeleteWorkflowExecution\n      /home/runner/work/docker-builds/docker-builds/temporal/common/persistence/visibility/visiblity_manager_metrics.go:135\n    go.temporal.io/server/service/history.(*visibilityQueueTaskExecutor).processDeleteExecution\n      /home/runner/work/docker-builds/docker-builds/temporal/service/history/visibility_queue_task_executor.go:360\n    go.temporal.io/server/service/history.(*visibilityQueueTaskExecutor).Execute\n      /home/runner/work/docker-builds/docker-builds/temporal/service/history/visibility_queue_task_executor.go:129\n    go.temporal.io/server/service/history/queues.(*executableImpl).Execute\n      /home/runner/work/docker-builds/docker-builds/temporal/service/history/queues/executable.go:374\n    go.temporal.io/server/common/tasks.(*FIFOScheduler[...]).executeTask.func1\n      /home/runner/work/docker-builds/docker-builds/temporal/common/tasks/fifo_scheduler.go:223\n    go.temporal.io/server/common/backoff.ThrottleRetry.func1\n      /home/runner/work/docker-builds/docker-builds/temporal/common/backoff/retry.go:62\n    go.temporal.io/server/common/backoff.ThrottleRetryContext\n      /home/runner/work/docker-builds/docker-builds/temporal/common/backoff/retry.go:89\n    go.temporal.io/server/common/backoff.ThrottleRetry\n      /home/runner/work/docker-builds/docker-builds/temporal/common/backoff/retry.go:63\n    go.temporal.io/server/common/tasks.(*FIFOScheduler[...]).executeTask\n      /home/runner/work/docker-builds/docker-builds/temporal/common/tasks/fifo_scheduler.go:233\n    go.temporal.io/server/common/tasks.(*FIFOScheduler[...]).processTask\n      /home/runner/work/docker-builds/docker-builds/temporal/common/tasks/fifo_scheduler.go:211\",\n    \"level\": \"error\",\n    \"logging-call-at\": \"/home/runner/work/docker-builds/docker-builds/temporal/common/persistence/visibility/visiblity_manager_metrics.go:217\",\n    \"ts\": \"2025-07-30T04:28:54.046Z\",\n    \"error\": \"context deadline exceeded\"\n  }\n  ```\n- \"Critical error processing task, retrying\" logs with `unable to delete custom search attributes: context deadline exceeded`. Example:\n  ```json\n  {\n    \"unexpected-error-attempts\": 69,\n    \"queue-task-type\": \"VisibilityDeleteExecution\",\n    \"shard-id\": 441,\n    \"address\": \"10.160.48.225:7234\",\n    \"wf-namespace-id\": \"e8ded80f-c3e7-43d8-9061-3fe119bda9ed\",\n    \"level\": \"error\",\n    \"wf-id\": \"autoRotateSignerAuthorities/t-yaimdsom6j/td-axmffjrsje-2025-07-13T16:25:00Z\",\n    \"wf-history-event-id\": 0,\n    \"queue-task\": \"e8ded80f-c3e7-43d8-9061-3fe119bda9ed/autoRotateSignerAuthorities/t-yaimdsom6j/td-axmffjrsje-2025-07-13T16:25:00Z/0198049b-415b-7910-8d88-e351db0fc0a9\",\n    \"logging-call-at\": \"/home/runner/work/docker-builds/docker-builds/temporal/common/log/lazy_logger.go:68\",\n    \"attempt\": 70,\n    \"wf-run-id\": \"0198049b-415b-7910-8d88-e351db0fc0a9\",\n    \"component\": \"visibility-queue-processor\",\n    \"queue-task-key\": {\n      \"FireTime\": \"1970-01-01T00:00:00Z\",\n      \"TaskID\": 817889465\n    },\n    \"stacktrace\": \"go.temporal.io/server/common/log.(*zapLogger).Error\n      /home/runner/work/docker-builds/docker-builds/temporal/common/log/zap_logger.go:154\n    go.temporal.io/server/common/log.(*lazyLogger).Error\n      /home/runner/work/docker-builds/docker-builds/temporal/common/log/lazy_logger.go:68\n    go.temporal.io/server/service/history/queues.(*executableImpl).HandleErr.func1\n      /home/runner/work/docker-builds/docker-builds/temporal/service/history/queues/executable.go:535\n    go.temporal.io/server/service/history/queues.(*executableImpl).HandleErr\n      /home/runner/work/docker-builds/docker-builds/temporal/service/history/queues/executable.go:599\n    go.temporal.io/server/common/tasks.(*FIFOScheduler[...]).executeTask.func1\n      /home/runner/work/docker-builds/docker-builds/temporal/common/tasks/fifo_scheduler.go:224\n    go.temporal.io/server/common/backoff.ThrottleRetry.func1\n      /home/runner/work/docker-builds/docker-builds/temporal/common/backoff/retry.go:62\n    go.temporal.io/server/common/backoff.ThrottleRetryContext\n      /home/runner/work/docker-builds/docker-builds/temporal/common/backoff/retry.go:89\n    go.temporal.io/server/common/backoff.ThrottleRetry\n      /home/runner/work/docker-builds/docker-builds/temporal/common/backoff/retry.go:63\n    go.temporal.io/server/common/tasks.(*FIFOScheduler[...]).executeTask\n      /home/runner/work/docker-builds/docker-builds/temporal/common/tasks/fifo_scheduler.go:233\n    go.temporal.io/server/common/tasks.(*FIFOScheduler[...]).processTask\n      /home/runner/work/docker-builds/docker-builds/temporal/common/tasks/fifo_scheduler.go:211\",\n    \"operation-result\": \"OperationCritical\",\n    \"ts\": \"2025-07-30T03:56:31.010Z\",\n    \"error\": \"unable to delete custom search attributes: context deadline exceeded\"\n  }\n  ```\n\nI also found lots of warnings with the message \"List query exceeded threshold\" during subsequent deletion attempts. Example:\n\n```json\n{\n  \"visibility-query\": \"CloseTime < \\\"2025-07-22T00:00:00Z\\\"\",\n  \"level\": \"warn\",\n  \"logging-call-at\": \"/home/runner/work/docker-builds/docker-builds/temporal/common/persistence/visibility/visiblity_manager_metrics.go:146\",\n  \"ts\": \"2025-07-30T11:38:27.315Z\",\n  \"namepsace\": \"default\",\n  \"duration\": 1.968041448\n}\n```\n\n## Steps to Reproduce the Problem\n\n1. Set up Temporal cluster with any number of closed workflows.\n2. Run batch delete command on a small subset: `temporal workflow delete --query 'CloseTime > \"YYYY-MM-DDTHH:MM:SSZ\" AND CloseTime < \"YYYY-MM-DDTHH:MM:SSZ\"' --rps 5`.\n3. Observe batch job completes successfully with `completeOperationCount == totalOperationCount`.\n4. Verify actual deletion with `temporal workflow count` using the same query.\n5. Notice all workflows remain despite successful batch completion.\n6. Issue persists across all batch sizes (tested from 56 to 540k workflows).\n\n## Specifications\n\n- **Version:** 1.27.2.\n- **Platform:** Kubernetes (Helm chart 0.63.0), MySQL v8 (Amazon RDS), 512 shards.\n- **Environment:** The Kubernetes deployments (frontend, worker, history, matching, web) have 3 pods each.\n\n## Additional context\n\n- Issue appears systematically related to visibility store operations timing out during deletions (similar to #6995), but batch job incorrectly reports these timeouts as successful completions rather than failures. \n- [I originally reported this on the forum](https://community.temporal.io/t/workflow-deletion-batch-job-fails-despite-reporting-successful-completion/18057), where I also included screenshots of the DB metrics. The problem is not volume-dependent as initially suspected.","closedAt":"2025-07-31T17:23:14Z","comments":[{"id":"IC_kwDODNqesM67K8K_","author":{"login":"bergundy"},"authorAssociation":"MEMBER","body":"Thanks for reporting, we are looking into this and will report back.","createdAt":"2025-07-31T14:29:13Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"HEART","users":{"totalCount":1}}],"url":"https://github.com/temporalio/temporal/issues/8125#issuecomment-3140207295","viewerDidAuthor":false},{"id":"IC_kwDODNqesM67NGxL","author":{"login":"bergundy"},"authorAssociation":"MEMBER","body":"Workflow deletion is an async operation, it's actually just requesting that the workflow be deleted and not waiting for actual deletion. Looks like in your case timeouts in your persistence layer are preventing workflows from being deleted, the issue is not with the deletion or batch APIs.\n\nThe API documentation mentions that deletion is async but we should consider adding a synchronous deletion API, which is not a trivial task.\n\nI'm closing this issue since the feature works as expected.","createdAt":"2025-07-31T17:23:14Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/8125#issuecomment-3140774987","viewerDidAuthor":false}],"createdAt":"2025-07-31T09:45:22Z","labels":[{"id":"MDU6TGFiZWwyMDE5ODE3MzQ2","name":"potential-bug","description":"","color":"66b9cc"}],"milestone":null,"number":8125,"reactionGroups":[],"state":"CLOSED","title":"Workflow deletion batch jobs report successful completion but fail to actually delete workflows","updatedAt":"2025-07-31T17:23:14Z","url":"https://github.com/temporalio/temporal/issues/8125"}
