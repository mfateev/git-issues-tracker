{"assignees":[],"author":{"id":"MDQ6VXNlcjM1MTEwNTcx","is_bot":false,"login":"raghudeshu","name":""},"body":"## Expected Behavior\r\n\r\nWe have a 3 node cluster Even when one node is down we are expecting the temporal to work by connecting to other two nodes.\r\n\r\n## Actual Behavior:\r\nWe are doing the load test and we observed Temporal is not able to connect to Cassandra even when ONE node is down\r\n\r\n\r\n## Steps to Reproduce the Problem\r\n\r\n  1. In a cluster make sure one node in Cassandra is down. The temporal pods are not able to connect to remaining other two nodes.\r\n\r\nError:\r\n2022/04/14 23:41:44 error: failed to connect to XX.XXX.XX.7:9042 due to error: write tcp XX.XXX.XX.79:44342->XX.XXX.XX.7:9042: write: connection reset by peer\r\nunable to dial control conn XX.XXX.XX.7:9042 gocql: no response received from cassandra within timeout period\r\n\r\nBelow is my Configuration:\r\n\r\ncassandra:\r\nhosts: [“XX.XXX.XX.7,XX.XXX.XX.9,XX.XXX.XX.10”]\r\nport: 9042\r\nkeyspace: temporal\r\nuser: “temporal”\r\npassword: “XXXXXXX”\r\nexistingSecret: “”\r\nreplicationFactor: 3 (Tried both 1 and 3)\r\nconsistency:\r\ndefault:\r\nconsistency: “local_quorum”\r\nserialConsistency: “local_serial”\r\ntls:\r\nenabled: true\r\nenableHostVerification: false\r\n\r\nNote: We are mentioning the cluster info with comma separated ip’s. We did updated Replication factor with 1 ,3 both did not worked.\r\n\r\n## Specifications\r\n\r\n  - Version: 1.13\r\n  - Platform: Temporal is deployed in Azure . Cassandra is managed by [azure]\r\n\r\nCassandra Configuration:\r\n\r\n\r\n![MicrosoftTeams-image (1)](https://user-images.githubusercontent.com/35110571/163580027-8f383bbf-456b-41f1-8874-6739091d4afe.png)\r\n\r\n","closedAt":null,"comments":[{"id":"IC_kwDODNqesM5BmAGg","author":{"login":"yiminc"},"authorAssociation":"MEMBER","body":"@raghudeshu , when Cassandra is overloaded, sometime you might encounter that problem. If you lower your load, temporal server should be able to function even if Cassandra lost one node.\r\nAlso, please upgrade to latest version for your load test, there have been many improvement/bugfixes since 1.13.\r\n","createdAt":"2022-04-16T00:19:34Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2729#issuecomment-1100480928","viewerDidAuthor":false},{"id":"IC_kwDODNqesM5bRPPM","author":{"login":"johanforssell"},"authorAssociation":"NONE","body":"I've had the exact same problem. Temporal **1.18.5**.\r\n\r\nAlso, when all three nodes came up again, we have the following errors in the **Frontend** servers. We've had these errors for days.\r\n```\r\n2023/05/02 10:29:51 gocql: unable to dial control conn x.x.x.133:9042: dial tcp x.x.x.165:9042: i/o timeout\r\n2023/05/02 10:29:51 gocql: unable to dial control conn x.x.x.133:9042: dial tcp x.x.x.133:9042: i/o timeout\r\n2023/05/02 10:29:51 gocql: unable to dial control conn x.x.x.133:9042: dial tcp x.x.x.197:9042: i/o timeout\r\n```\r\n\r\nMore specifically:\r\n\r\n`gocql: unable to create session: unable to connect to initial hosts: dial tcp x.x.x.165:9042: i/o timeout`\r\n```\r\n{\"level\":\"error\",\"ts\":\"2023-05-02T10:32:17.328Z\",\"msg\":\"gocql wrapper: unable to refresh gocql session\",\"error\":\"gocql: unable to create session: unable to connect to initial hosts: dial tcp x.x.x.165:9042: i/o timeout\",\"logging-call-at\":\"session.go:99\",\"stacktrace\":\"go.temporal.io/server/common/log.(*zapLogger).Error\\n\\t/home/builder/temporal/common/log/zap_logger.go:143\\ngo.temporal.io/server/common/persistence/nosql/nosqlplugin/cassandra/gocql.(*session).refresh\\n\\t/home/builder/temporal/common/persistence/nosql/nosqlplugin/cassandra/gocql/session.go:99\\ngo.temporal.io/server/common/persistence/nosql/nosqlplugin/cassandra/gocql.(*session).handleError\\n\\t/home/builder/temporal/common/persistence/nosql/nosqlplugin/cassandra/gocql/session.go:191\\ngo.temporal.io/server/common/persistence/nosql/nosqlplugin/cassandra/gocql.(*iter).Close.func1\\n\\t/home/builder/temporal/common/persistence/nosql/nosqlplugin/cassandra/gocql/iter.go:56\\ngo.temporal.io/server/common/persistence/nosql/nosqlplugin/cassandra/gocql.(*iter).Close\\n\\t/home/builder/temporal/common/persistence/nosql/nosqlplugin/cassandra/gocql/iter.go:58\\ngo.temporal.io/server/common/persistence/cassandra.(*ClusterMetadataStore).ListClusterMetadata\\n\\t/home/builder/temporal/common/persistence/cassandra/cluster_metadata_store.go:120\\ngo.temporal.io/server/common/persistence.(*clusterMetadataManagerImpl).ListClusterMetadata\\n\\t/home/builder/temporal/common/persistence/clusterMetadataStore.go:127\\ngo.temporal.io/server/common/persistence.(*clusterMetadataRateLimitedPersistenceClient).ListClusterMetadata\\n\\t/home/builder/temporal/common/persistence/persistenceRateLimitedClients.go:993\\ngo.temporal.io/server/common/persistence.(*clusterMetadataPersistenceClient).ListClusterMetadata\\n\\t/home/builder/temporal/common/persistence/persistenceMetricClients.go:1393\\ngo.temporal.io/server/common/persistence.(*clusterMetadataRetryablePersistenceClient).ListClusterMetadata.func1\\n\\t/home/builder/temporal/common/persistence/persistenceRetryableClients.go:972\\ngo.temporal.io/server/common/backoff.ThrottleRetryContext\\n\\t/home/builder/temporal/common/backoff/retry.go:194\\ngo.temporal.io/server/common/persistence.(*clusterMetadataRetryablePersistenceClient).ListClusterMetadata\\n\\t/home/builder/temporal/common/persistence/persistenceRetryableClients.go:976\\ngo.temporal.io/server/common/cluster.(*metadataImpl).listAllClusterMetadataFromDB.func1\\n\\t/home/builder/temporal/common/cluster/metadata.go:517\\ngo.temporal.io/server/common/collection.(*PagingIteratorImpl[...]).getNextPage\\n\\t/home/builder/temporal/common/collection/pagingIterator.go:116\\ngo.temporal.io/server/common/collection.NewPagingIterator[...]\\n\\t/home/builder/temporal/common/collection/pagingIterator.go:52\\ngo.temporal.io/server/common/cluster.(*metadataImpl).listAllClusterMetadataFromDB\\n\\t/home/builder/temporal/common/cluster/metadata.go:534\\ngo.temporal.io/server/common/cluster.(*metadataImpl).refreshClusterMetadata\\n\\t/home/builder/temporal/common/cluster/metadata.go:404\\ngo.temporal.io/server/common/cluster.(*metadataImpl).refreshLoop\\n\\t/home/builder/temporal/common/cluster/metadata.go:391\\ngo.temporal.io/server/internal/goro.(*Handle).Go.func1\\n\\t/home/builder/temporal/internal/goro/goro.go:64\"}\r\n```\r\n\r\nAnd `operation ListClusterMetadata encountered gocql: no hosts available in the pool`\r\n```\r\n{\"level\":\"error\",\"ts\":\"2023-05-02T10:32:17.329Z\",\"msg\":\"Operation failed with internal error.\",\"error\":\"operation ListClusterMetadata encountered gocql: no hosts available in the pool\",\"metric-scope\":81,\"logging-call-at\":\"persistenceMetricClients.go:1579\",\"stacktrace\":\"go.temporal.io/server/common/log.(*zapLogger).Error\\n\\t/home/builder/temporal/common/log/zap_logger.go:143\\ngo.temporal.io/server/common/persistence.(*metricEmitter).updateErrorMetric\\n\\t/home/builder/temporal/common/persistence/persistenceMetricClients.go:1579\\ngo.temporal.io/server/common/persistence.(*clusterMetadataPersistenceClient).ListClusterMetadata\\n\\t/home/builder/temporal/common/persistence/persistenceMetricClients.go:1397\\ngo.temporal.io/server/common/persistence.(*clusterMetadataRetryablePersistenceClient).ListClusterMetadata.func1\\n\\t/home/builder/temporal/common/persistence/persistenceRetryableClients.go:972\\ngo.temporal.io/server/common/backoff.ThrottleRetryContext\\n\\t/home/builder/temporal/common/backoff/retry.go:194\\ngo.temporal.io/server/common/persistence.(*clusterMetadataRetryablePersistenceClient).ListClusterMetadata\\n\\t/home/builder/temporal/common/persistence/persistenceRetryableClients.go:976\\ngo.temporal.io/server/common/cluster.(*metadataImpl).listAllClusterMetadataFromDB.func1\\n\\t/home/builder/temporal/common/cluster/metadata.go:517\\ngo.temporal.io/server/common/collection.(*PagingIteratorImpl[...]).getNextPage\\n\\t/home/builder/temporal/common/collection/pagingIterator.go:116\\ngo.temporal.io/server/common/collection.NewPagingIterator[...]\\n\\t/home/builder/temporal/common/collection/pagingIterator.go:52\\ngo.temporal.io/server/common/cluster.(*metadataImpl).listAllClusterMetadataFromDB\\n\\t/home/builder/temporal/common/cluster/metadata.go:534\\ngo.temporal.io/server/common/cluster.(*metadataImpl).refreshClusterMetadata\\n\\t/home/builder/temporal/common/cluster/metadata.go:404\\ngo.temporal.io/server/common/cluster.(*metadataImpl).refreshLoop\\n\\t/home/builder/temporal/common/cluster/metadata.go:391\\ngo.temporal.io/server/internal/goro.(*Handle).Go.func1\\n\\t/home/builder/temporal/internal/goro/goro.go:64\"}\r\n```","createdAt":"2023-05-02T10:35:46Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2729#issuecomment-1531245516","viewerDidAuthor":false},{"id":"IC_kwDODNqesM5bhZPS","author":{"login":"hema-kishore-gunda"},"authorAssociation":"NONE","body":"We have hit the exact same problem. We have cassandra 3 node with pod disruption allowed as 1. We had a cluster upgrade where in we had 2 out of 3 cassandra nodes were available and the temporal server pods were restarted as part of upgrade. Old pods have been terminated and the new pods were failing to load with out any error message on the logs. Server pods have started working once all the cassandra nodes have been completely restarted. \r\n\r\nThis issue exists on the latest version(1.20.2) of the temporal server as well. \r\n\r\n<img width=\"1009\" alt=\"image\" src=\"https://user-images.githubusercontent.com/70211877/236341249-b32e1599-0df9-449c-8723-6fd7a95a7fbe.png\">\r\n","createdAt":"2023-05-04T22:18:10Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2729#issuecomment-1535480786","viewerDidAuthor":false},{"id":"IC_kwDODNqesM5lA9Uy","author":{"login":"yiminc"},"authorAssociation":"MEMBER","body":"It maybe fixed by gocql 1.4.0 https://github.com/gocql/gocql/releases/tag/v1.4.0 which is included in temporal server v1.21.5","createdAt":"2023-08-27T20:08:03Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2729#issuecomment-1694750002","viewerDidAuthor":false},{"id":"IC_kwDODNqesM5ompSs","author":{"login":"mustaFAB53"},"authorAssociation":"NONE","body":"We are connecting to an existing cassandra setup and seeing this issue even for latest temporal image with tag v1.21.5","createdAt":"2023-10-10T10:35:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2729#issuecomment-1754961068","viewerDidAuthor":false},{"id":"IC_kwDODNqesM5r2btW","author":{"login":"yiminc"},"authorAssociation":"MEMBER","body":"From the error message, it seems even if the config provided multiple IP addresses as hosts, the gocql still fail to connect even if a single host was down. We log the error when try to [reconnect](https://github.com/temporalio/temporal/blob/1f497134f668aecad766a263895bd1f3f4d40bbc/common/persistence/nosql/nosqlplugin/cassandra/gocql/session.go#L107). From the above message, `\"gocql wrapper: unable to refresh gocql session\",\"error\":\"gocql: unable to create session: unable to connect to initial hosts: dial tcp x.x.x.165:9042: i/o timeout\"`, it seems either there is only [one host configured](https://github.com/temporalio/temporal/blob/1f497134f668aecad766a263895bd1f3f4d40bbc/common/persistence/nosql/nosqlplugin/cassandra/gocql/client.go#L51-L53) or the gocql driver is not working as expected. \r\n\r\n","createdAt":"2023-11-14T02:12:59Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2729#issuecomment-1809431382","viewerDidAuthor":false}],"createdAt":"2022-04-15T14:02:48Z","labels":[{"id":"MDU6TGFiZWwyMDE5ODE3MzQ2","name":"potential-bug","description":"","color":"66b9cc"}],"milestone":null,"number":2729,"reactionGroups":[],"state":"OPEN","title":"Temporal Is not able to connect to Cassandra even when one node is down in a cluster","updatedAt":"2023-11-14T02:12:59Z","url":"https://github.com/temporalio/temporal/issues/2729"}
