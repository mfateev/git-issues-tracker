{"assignees":[],"author":{"id":"MDQ6VXNlcjMxMjQ1MTQw","is_bot":false,"login":"eldondevat","name":""},"body":"## Expected Behavior\nDev Server runs successfully\n\n\n## Actual Behavior\nServer returns 500's. We are continuing to see #3784 on the 1.27 container from docker hub.\n\nAbout an hour after the server starts (mostly idle), we see our first error:\n```\n\n| Jul 3, 2025 @ 03:00:19.000 | time=2025-07-03T03:00:19.926 level=ERROR msg=\"Persistent store operation failure\" component=matching-engine wf-task-queue-name=/_sys/lumpers/3 wf-task-queue-type=Workflow wf-namespace=redacted worker-build-id=_unversioned_ store-operation=update-task-queue error=\"Failed to lock task queue. Error: context canceled\" \n| Jul 3, 2025 @ 00:01:00.000 | time=2025-07-03T00:01:00.743 level=WARN msg=\"RecordActivityHeartbeat with error\" service=worker Namespace=temporal-system TaskQueue=temporal-sys-tq-scanner-taskqueue-0 WorkerID=temporal-system@127.0.0.1:35823 ActivityID=5 ActivityType=temporal-sys-tq-scanner-scvg-activity Attempt=1 WorkflowType=temporal-sys-tq-scanner-workflow WorkflowID=temporal-sys-tq-scanner RunID=0197cc9b-0a93-72a7-8dd6-656fc14c0f2b Error=\"context canceled\"\n| Jul 2, 2025 @ 20:16:08.000 | time=2025-07-02T20:16:08.912 level=ERROR msg=\"Persistent store operation failure\" component=matching-engine wf-task-queue-name=/_sys/default-worker-tq/2 wf-task-queue-type=Workflow wf-namespace=temporal-system worker-build-id=_unversioned_ store-operation=update-task-queue error=\"context canceled\"\n| Jul 2, 2025 @ 19:26:43.000 | CLI 0.0.0-DEV (Server 1.27.0, UI 2.36.0)\n| Jul 2, 2025 @ 19:26:43.000 |  \n| Jul 2, 2025 @ 19:26:43.000 | Server:  0.0.0.0:7233\n| Jul 2, 2025 @ 19:26:43.000 | UI:      http://0.0.0.0:8233\n| Jul 2, 2025 @ 19:26:43.000 | Metrics: http://0.0.0.0:46023/metrics\n```\n\nSeveral days later, the logs start spewing errors:\n\n```\n\n  | Jul 7, 2025 @ 05:01:22.000 | time=2025-07-07T05:01:22.697 level=ERROR msg=\"Queue reader unable to retrieve tasks\" shard-id=1 address=127.0.0.1:42567 component=outbound-queue-processor queue-reader-id=0 error=\"GetHistoryTasks operation failed. Select failed. CategoryID: 7. Error: context deadline exceeded\"\n  | Jul 7, 2025 @ 05:01:19.000 | time=2025-07-07T05:01:19.874 level=ERROR msg=\"Operation failed with internal error.\" error=\"GetTransferTasks operation failed. Select failed. Error: context deadline exceeded\" error-type=serviceerror.Unavailable operation=GetTransferTasks\n  | Jul 7, 2025 @ 05:01:19.000 | time=2025-07-07T05:01:19.874 level=ERROR msg=\"Queue reader unable to retrieve tasks\" shard-id=1 address=127.0.0.1:42567 component=transfer-queue-processor queue-reader-id=0 error=\"GetTransferTasks operation failed. Select failed. Error: context deadline exceeded\"\n  | Jul 7, 2025 @ 05:01:17.000 | time=2025-07-07T05:01:17.647 level=ERROR msg=\"Queue reader unable to retrieve tasks\" shard-id=1 address=127.0.0.1:42567 component=outbound-queue-processor queue-reader-id=0 error=\"GetHistoryTasks operation failed. Select failed. CategoryID: 7. Error: context deadline exceeded\"\n  | Jul 7, 2025 @ 05:01:17.000 | time=2025-07-07T05:01:17.639 level=ERROR msg=\"Operation failed with internal error.\" error=\"GetHistoryTasks operation failed. Select failed. CategoryID: 7. Error: context deadline exceeded\" error-type=serviceerror.Unavailable operation=GetOutboundTasks\n  | Jul 7, 2025 @ 04:10:01.000 | time=2025-07-07T04:10:01.299 level=ERROR msg=\"Update workflow execution operation failed.\" shard-id=1 address=127.0.0.1:42567 wf-namespace-id=25d94d12-0790-4ec5-9806-391348e9d17e wf-id=redacted.health.healthCheck-2025-07-07T04:10:00Z wf-run-id=0197e313-92d9-747d-a17c-b2251034f251 store-operation=update-wf-execution error=\"context canceled\"\n\n```\n\n## Steps to Reproduce the Problem\n\n1) Start dev server\n2) Wait\n\n\n\n\n## Specifications\n\n  - Version: 1.27\n  - Platform: Docker-compose running the temporal docker image\n","closedAt":"2025-09-18T22:40:22Z","comments":[{"id":"IC_kwDODNqesM61iC6g","author":{"login":"eldondevat"},"authorAssociation":"NONE","body":"I am planning on updating these to run 1.28 this week, I will follow up if we continue to see this.","createdAt":"2025-07-07T15:20:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/8017#issuecomment-3045600928","viewerDidAuthor":false},{"id":"IC_kwDODNqesM6_d6CQ","author":{"login":"yycptt"},"authorAssociation":"MEMBER","body":"@eldondevat Do you see the same issue with 1.28.1? \n\nI don't see errors like \"no such table\" or \"missing table\" in the logs you pasted. Looks like they are all transient timeout errors.","createdAt":"2025-08-21T22:47:18Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/8017#issuecomment-3212288144","viewerDidAuthor":false},{"id":"IC_kwDODNqesM7FSWdN","author":{"login":"bergundy"},"authorAssociation":"MEMBER","body":"Closing since there is no followup.","createdAt":"2025-09-18T22:40:22Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/8017#issuecomment-3309922125","viewerDidAuthor":false}],"createdAt":"2025-07-07T15:18:52Z","labels":[{"id":"MDU6TGFiZWwyMDE5ODE3MzQ2","name":"potential-bug","description":"","color":"66b9cc"}],"milestone":null,"number":8017,"reactionGroups":[],"state":"CLOSED","title":"SQLite failed due to missing DB table","updatedAt":"2025-09-18T22:40:22Z","url":"https://github.com/temporalio/temporal/issues/8017"}
