{"assignees":[],"author":{"id":"MDQ6VXNlcjE4MTA0MTY3","is_bot":false,"login":"hafiz-qasim","name":"Hafiz Qasim"},"body":"Hi Temporal team and community,\n\nI’m trying to understand whether it’s realistically possible to run Temporal on Kubernetes in a way that keeps the history service memory usage stable and within limits, without eventually hitting OOM kills.\n\nEnvironment\n\t•\tTemporal version: 1.29.1\n\t•\tPersistence: PostgreSQL\n\t•\tDeployment: Kubernetes\n\t•\tHistory service replicas: 1\n\t•\tShards: tried multiple values\n\t•\tMonitoring: Grafana community dashboard for Temporal server\n\nLoad model\n\t•\tExecute 100 workflows per minute, evenly distributed\n\t•\tAfter each minute of execution: 1 minute sleep\n\t•\tAfter 15 cycles, there is a 30-minute idle period\n\t•\tThis pattern repeats\n\nWhat I’ve tried, adjusting:\n\t•\tNumber of shards\n\t•\tHistory and events cache settings\n\t•\tDatabase connection pool sizes\n\t•\tVerifying via Grafana that traffic drops during idle periods\n\nObserved behavior\n\t•\tHistory pod memory usage continuously accumulates over time\n\t•\tMemory does not stabilize or decrease, even during idle periods\n\t•\tEventually the history pod is OOM killed\n\t•\tI don’t see a clear plateau in memory usage in Grafana\n\nMain question\nHas anyone successfully deployed Temporal on Kubernetes such that the history service memory remains stable over time (especially under cyclical or bursty workloads), without relying on restarts or OOM recovery?\n\nIf so:\n\t•\tWhat configuration patterns made the difference?\n\t•\tIs multiple history replicas required for memory stability?\n\t•\tAre there known limitations or expected behavior around cache eviction / GC in this scenario?\n\nI’d appreciate any guidance, references, or confirmation of whether this is expected behavior or a misconfiguration on my side.\n\nThanks in advance!\n","closedAt":null,"comments":[{"id":"IC_kwDODNqesM7eK76C","author":{"login":"andropler"},"authorAssociation":"NONE","body":"I'm also interested in this issue. \nI was able to configure the history cache settings to handle traffic stably without OOM by setting the mutable cache in count units, the event cache in capacity units, and applying the GOMEMLIMIT setting. However, as soon as I set the mutable cache in capacity units, the history pod significantly exceeds the configured cache capacity, even surpasses the GOMEMLIMIT, and gets restarted due to OOM. This was on the latest version 1.29.1, and I'd like to know the solution to this issue.\nI've been struggling with this issue for several weeks now, and although I posted about it in the community, I haven't received any particularly helpful responses.\nLink: https://community.temporal.io/t/memory-oom-issues-with-history-pod-and-size-based-cache-configuration/18787\nI would greatly appreciate it if the official Temporal developers could take an interest in this issue.","createdAt":"2026-01-09T06:28:50Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/8902#issuecomment-3727408770","viewerDidAuthor":false}],"createdAt":"2025-12-24T10:03:38Z","labels":[],"milestone":null,"number":8902,"reactionGroups":[],"state":"OPEN","title":"History service memory usage upward trend","updatedAt":"2026-01-09T06:28:50Z","url":"https://github.com/temporalio/temporal/issues/8902"}
