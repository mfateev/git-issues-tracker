{"assignees":[],"author":{"id":"MDQ6VXNlcjE3NTA2NDQx","is_bot":false,"login":"rfwagner","name":"Richard Wagner"},"body":"## Expected Behavior\r\n\r\nIn our setup we are archiving to an S3 compliant object store. Latency to the S3 store is fairly low. I expect the vast majority of S3 calls to succeed w/o timeout.\r\n\r\n## Actual Behavior\r\n\r\nWe are seeing very frequent timeouts in the S3 archival calls. Some sample logs included below. From the setting of `defaultBlobstoreTimeout` in `s3store/historyArchiver.go`, it seems like the general intent is to enforce a timeout of one minute on the S3 API calls. I put some print statements in `ensureContextTimeout` and I can see that in many cases the deadline in place at the time of the S3 calls is just under 60s. But in other cases, the deadline in the context being used for the S3 calls is under 1s. Presumably the timeouts are happening when this is the case, though I haven't been able to verify that for sure.\r\n\r\nIn any case it seems like it would be beneficial to ensure that a consistent deadline is enforced on all S3 API calls.\r\n\r\n## Steps to Reproduce the Problem\r\n\r\n  1. Configure a namespace for S3 archiving.\r\n  1. Set retention period to 0 so archiving happens immediately and can be easily tested.\r\n  1. Execute several workflows and observe a large number of timeouts on the S3 calls.\r\n\r\n## Specifications\r\n\r\n  - Version: 0.29\r\n  - Platform: MacOS\r\n\r\nHere are a few logs:\r\n```\r\n{\"level\":\"error\",\"ts\":\"2020-10-02T10:02:23.350-0700\",\"msg\":\"Archive method encountered an non-retryable error.\",\"service\":\"history\",\"archival-request-namespace-id\":\"c52608e8-2d17-468c-b940-369bba914c91\",\"archival-request-namespace\":\"rtest\",\"archival-request-workflow-id\":\"deb097c6-f862-415d-82e2-4763a2f139ca-host0\",\"archival-request-run-id\":\"874a451a-4112-44f1-8ed8-759ab22e9768\",\"archival-request-workflow-type\":\"upgradeSingleHost\",\"archival-request-close-timestamp\":\"2020-10-02T17:02:23.050Z\",\"archival-request-status\":\"Completed\",\"archival-URI\":\"s3://testb1\",\"archival-archive-fail-reason\":\"failed to write history to s3\",\"error\":\"RequestCanceled: request context canceled\\ncaused by: context deadline exceeded\",\"logging-call-at\":\"visibilityArchiver.go:120\",\"stacktrace\":\"go.temporal.io/server/common/log/loggerimpl.(*loggerImpl).Error\\n\\t/Users/rwagner/go/src/github.com/temporalio/temporal/common/log/loggerimpl/logger.go:138\\ngo.temporal.io/server/common/archiver/s3store.(*visibilityArchiver).Archive.func1\\n\\t/Users/rwagner/go/src/github.com/temporalio/temporal/common/archiver/s3store/visibilityArchiver.go:120\\ngo.temporal.io/server/common/archiver/s3store.(*visibilityArchiver).Archive\\n\\t/Users/rwagner/go/src/github.com/temporalio/temporal/common/archiver/s3store/visibilityArchiver.go:149\\ngo.temporal.io/server/service/worker/archiver.(*client).archiveVisibilityInline\\n\\t/Users/rwagner/go/src/github.com/temporalio/temporal/service/worker/archiver/client.go:250\"}\r\n{\"level\":\"info\",\"ts\":\"2020-10-02T10:02:23.384-0700\",\"msg\":\"failed to perform visibility archival inline\",\"service\":\"history\",\"shard-id\":4,\"address\":\"127.0.0.1:7234\",\"shard-item\":\"0xc00101b000\",\"archival-caller-service-name\":\"history\",\"archival-archive-attempted-inline\":true,\"archival-request-namespace-id\":\"c52608e8-2d17-468c-b940-369bba914c91\",\"archival-request-namespace\":\"rtest\",\"archival-request-workflow-id\":\"deb097c6-f862-415d-82e2-4763a2f139ca-host0\",\"archival-request-run-id\":\"874a451a-4112-44f1-8ed8-759ab22e9768\",\"archival-URI\":\"s3://testb1\",\"error\":\"RequestCanceled: request context canceled\\ncaused by: context deadline exceeded\",\"logging-call-at\":\"client.go:235\"}\r\n{\"level\":\"error\",\"ts\":\"2020-10-02T10:02:23.366-0700\",\"msg\":\"Archive method encountered an non-retryable error.\",\"service\":\"history\",\"archival-request-namespace-id\":\"c52608e8-2d17-468c-b940-369bba914c91\",\"archival-request-namespace\":\"rtest\",\"archival-request-workflow-id\":\"deb097c6-f862-415d-82e2-4763a2f139ca-host1\",\"archival-request-run-id\":\"3253bb9b-507c-4814-83d4-d556e2cd0303\",\"archival-request-workflow-type\":\"upgradeSingleHost\",\"archival-request-close-timestamp\":\"2020-10-02T17:02:23.071Z\",\"archival-request-status\":\"Completed\",\"archival-URI\":\"s3://testb1\",\"archival-archive-fail-reason\":\"failed to write history to s3\",\"error\":\"RequestCanceled: request context canceled\\ncaused by: context deadline exceeded\",\"logging-call-at\":\"visibilityArchiver.go:120\",\"stacktrace\":\"go.temporal.io/server/common/log/loggerimpl.(*loggerImpl).Error\\n\\t/Users/rwagner/go/src/github.com/temporalio/temporal/common/log/loggerimpl/logger.go:138\\ngo.temporal.io/server/common/archiver/s3store.(*visibilityArchiver).Archive.func1\\n\\t/Users/rwagner/go/src/github.com/temporalio/temporal/common/archiver/s3store/visibilityArchiver.go:120\\ngo.temporal.io/server/common/archiver/s3store.(*visibilityArchiver).Archive\\n\\t/Users/rwagner/go/src/github.com/temporalio/temporal/common/archiver/s3store/visibilityArchiver.go:149\\ngo.temporal.io/server/service/worker/archiver.(*client).archiveVisibilityInline\\n\\t/Users/rwagner/go/src/github.com/temporalio/temporal/service/worker/archiver/client.go:250\"}\r\n```\r\n","closedAt":null,"comments":[{"id":"MDEyOklzc3VlQ29tbWVudDcxODk3Mzc2OQ==","author":{"login":"alexshtin"},"authorAssociation":"CONTRIBUTOR","body":"Thanks for reporting this and making partial investigation. `ensureContextTimeout` actually sets timeout to 1 minute only if it is not set at all. If it is set by caller then it stays as is. Logs you see are coming from \"inline\" archival feature when `Archive` is called right from timer and transfer task queue processor. Timeout values are set to [1 second](https://github.com/temporalio/temporal/blob/d280cc1dbf9cb9db7c13f631e8419c2aa5c08f87/service/history/service.go#L323) and [200 milliseconds](https://github.com/temporalio/temporal/blob/d280cc1dbf9cb9db7c13f631e8419c2aa5c08f87/service/history/service.go#L340) there. And I believe these error messages can be safely ignored because background worker will eventually archive workflow.\r\n\r\nNoisy error messages need to be fixed though. For now you can try to increase timeouts using dynamic config settings.","createdAt":"2020-10-29T19:31:51Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/787#issuecomment-718973769","viewerDidAuthor":false}],"createdAt":"2020-10-02T17:16:29Z","labels":[{"id":"MDU6TGFiZWwyMDE5ODE3MzQ2","name":"potential-bug","description":"","color":"66b9cc"},{"id":"MDU6TGFiZWwzMTM4ODI4MTE3","name":"up-for-grabs","description":"Issues to consider for external contribution","color":"69CD90"}],"milestone":null,"number":787,"reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"state":"OPEN","title":"Frequent timeouts while archiving to S3","updatedAt":"2021-07-04T07:12:57Z","url":"https://github.com/temporalio/temporal/issues/787"}
