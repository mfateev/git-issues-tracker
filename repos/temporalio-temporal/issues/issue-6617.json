{"assignees":[],"author":{"id":"MDQ6VXNlcjM2NDg3NTk2","is_bot":false,"login":"mohankurali","name":"mohan"},"body":"**Is your feature request related to a problem? Please describe.**\r\nCurrently, temporal design focuses on ensuring strong guarantees for workflow execution, which requires each event or activity result to be written immediately to the persistence store. For this reason, Temporal does not batch activities for bulk writes to Cassandra. To handle this, one needs to go for bigger persistence store cluster adding to the cost.\r\n\r\n**Describe the solution you'd like**\r\n\r\n1. Redis for Real-Time Workflow Execution State:\r\n\r\nPurpose: Redis can be used as a cache for workflow execution state and hot data (i.e., frequently accessed or recently updated data). Since Redis is an in-memory database, it provides low-latency reads and writes, making it ideal for workflows where immediate responsiveness is required.\r\n\r\nUse Case: Whenever a workflow is being executed, its current state, progress, and results of activities can be stored in Redis. Redis acts as a working memory, keeping active workflow states in memory for fast access during execution.\r\n\r\nPersistence in Redis: Redis persistence methods such as RDB snapshots or AOF can be used to periodically back up data to disk, but Redis itself would not be relied upon for full persistence.\r\n\r\nEviction Policy: Since Redis is memory-constrained, an eviction policy can be applied where old or less frequently used workflow data is offloaded to Cassandra after a certain threshold or TTL (time-to-live) period.\r\n\r\n2. Kafka for Event Streaming and Replay:\r\n\r\nPurpose: Kafka can be used to stream all workflow events and activity results for asynchronous processing and durable backup. If Redis crashes or the system needs to replay workflow histories, Kafka can be used to recover or reconstruct the exact event sequence.\r\n\r\nUse Case: Every change in workflow state (activity completion, task scheduling, etc.) is also streamed to Kafka as an event log. Kafka topics can be partitioned based on workflows or workflow shards to allow parallel processing.\r\n\r\nReplay Capability: Kafka acts as a reliable event log for replaying events in case Redis or Cassandra fails. If Redis loses the in-memory state, Temporal can replay workflow events from Kafka to restore the most recent workflow state in Redis.\r\n\r\nFault Tolerance: Kafka provides durable message storage and eventual consistency, ensuring that workflow states can be reconstructed by replaying the Kafka log, even after failures.\r\n\r\n3. Cassandra for Long-Term, Durable Storage:\r\n\r\nPurpose: Cassandra can be used as the durable, long-term persistence store for workflow history and state. This is critical for fault tolerance, event sourcing, and ensuring that even workflows that last for long periods can be recovered.\r\n\r\nUse Case: While Redis holds the real-time working state, Cassandra is responsible for storing the entire history of workflow execution, including every event that happened during the workflow lifecycle.\r\n\r\nBatch Writes: Cassandra can handle batch writes of workflow events and state transitions that are periodically written from Redis and Kafka. Redis acts as the in-memory cache, while Cassandra ensures that once a workflow completes or reaches certain checkpoints, its state is persisted for long-term storage.\r\n\r\nScalability: Cassandra provides horizontal scalability, allowing it to store huge amounts of workflow data, making it suitable for storing the event history and workflow results after Redis evicts data or when workflows are completed.\r\n\r\n\r\n","closedAt":null,"comments":[],"createdAt":"2024-10-07T19:53:15Z","labels":[{"id":"MDU6TGFiZWwxNjIxMDMwNzg3","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"milestone":null,"number":6617,"reactionGroups":[],"state":"OPEN","title":"hybrid architecture for Temporal","updatedAt":"2024-10-07T19:53:15Z","url":"https://github.com/temporalio/temporal/issues/6617"}
