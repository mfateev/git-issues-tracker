{"assignees":[],"author":{"id":"MDQ6VXNlcjE0NjM2MjI=","is_bot":false,"login":"mfateev","name":"Maxim Fateev"},"body":"**Is your feature request related to a problem? Please describe.**\r\nCurrently, task queue sync match is prioritized over backlog. So a task can sit in a backlog for a long time being starved by new tasks. Ideally task queues should try to deliver tasks in order. It is not possible to guarantee total ordering as multiple partitions and worker processes are involved, but not starving backlogged requests would greatly improve fairness of the system.\r\n\r\n**Describe the solution you'd like**\r\nDeliver tasks from backlog first. It can increase DB utilization as all tasks would need to be persisted in the case of a backlog. So we should consider if this should be an option of a task queue. I would try to avoid this and introduce such an option only if we see that DB load increase is significant after performance testing. \r\n","closedAt":"2025-12-31T01:30:00Z","comments":[{"id":"IC_kwDODNqesM4-MM6J","author":{"login":"paulnpdev"},"authorAssociation":"MEMBER","body":"I'm concerned about the dynamics of this.  I'm not sure if it's true in a realistic sense, but iiuc, when the system is database-throughput-constrained, under loads that the system *could* handle normally (because of the efficiency of sync-match) we would actually never catch up once we got into a backlog situation where every task has to be both written and read from the DB.\r\n\r\nMaybe we could be sophisticated and detect this case?  As long as we're making forward progress through time, prioritize backlog; if we are falling behind, prioritize sync-match?  A little complicated, yes.  But imho worth a little experimental coding to see *how* complicated.   Assuming that I'm understanding the dynamics correctly here.","createdAt":"2022-02-17T20:18:22Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-1043385993","viewerDidAuthor":false},{"id":"IC_kwDODNqesM4-MNjh","author":{"login":"dnr"},"authorAssociation":"MEMBER","body":"Sync match isn't prioritized over backlog right now. They both write into one go channel. I suppose the ratio will be tilted toward sync match since there could be multiple sync match writers and only one db writer, but backlog tasks should still get through. We talked about various potential changes to this last year and decided to wait until we had time to address all the concerns more holistically (avoiding starvation, ordering, avoiding increasing load further when load is already elevated).","createdAt":"2022-02-17T20:20:55Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-1043388641","viewerDidAuthor":false},{"id":"IC_kwDODNqesM5K0EXo","author":{"login":"mfateev"},"authorAssociation":"MEMBER","body":"I think we should have an option to not perform sync match if there is a backlog.","createdAt":"2022-09-22T15:06:45Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-1255163368","viewerDidAuthor":true},{"id":"IC_kwDODNqesM5l4Kd9","author":{"login":"ShahabT"},"authorAssociation":"MEMBER","body":"Starting to work on this. As the first step, I'm thinking to add a boolean dynamic config (per namespace+task queue) to allow disabling sync match when there is a backlog. Intention is to manually set this config only when the specific task queue requires FIFOish ordering.","createdAt":"2023-09-06T22:43:29Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-1709221757","viewerDidAuthor":false},{"id":"IC_kwDODNqesM5l9MAI","author":{"login":"paulnpdev"},"authorAssociation":"MEMBER","body":"what do you mean by \"manually\"?  Is the intent that a customer can\r\nprogrammatically set this?\r\n\r\nOn Wed, Sep 6, 2023 at 3:43 PM Shahab Tajik ***@***.***>\r\nwrote:\r\n\r\n> Starting to work on this. As the first step, I'm thinking to add a boolean\r\n> dynamic config (per namespace+task queue) to allow disabling sync match\r\n> when there is a backlog. Intention is to manually set this config only when\r\n> the specific task queue requires FIFOish ordering.\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/temporalio/temporal/issues/2517#issuecomment-1709221757>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AUMR7H2RBOUJGH2E7XN5NNTXZD4BZANCNFSM5OVPOTSQ>\r\n> .\r\n> You are receiving this because you commented.Message ID:\r\n> ***@***.***>\r\n>\r\n","createdAt":"2023-09-07T17:34:44Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-1710538760","viewerDidAuthor":false},{"id":"IC_kwDODNqesM5l9cte","author":{"login":"ShahabT"},"authorAssociation":"MEMBER","body":"@paulnpdev no, this config will not be exposed to the client (at least not now). Only the server operator can turn this flag on. Because this has implications on the load on the persistence layer, I do not think we can allow the customers turning it on, until the dynamics are fully understood as you mentioned.","createdAt":"2023-09-07T18:35:13Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-1710607198","viewerDidAuthor":false},{"id":"IC_kwDODNqesM5l9eJy","author":{"login":"paulnpdev"},"authorAssociation":"MEMBER","body":"ok for now!\r\nwill the flag be at the namespace level, the WF type level, or the TaskQ\r\nlevel\r\n\r\nOn Thu, Sep 7, 2023 at 11:35 AM Shahab Tajik ***@***.***>\r\nwrote:\r\n\r\n> @paulnpdev <https://github.com/paulnpdev> no, this config will not be\r\n> exposed to the client (at least not now). Only the server operator can turn\r\n> this flag on. Because this has implications on the load on the persistence\r\n> layer, I do not think we can allow the customers turning it on, until the\r\n> dynamics are fully understood as you mentioned.\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/temporalio/temporal/issues/2517#issuecomment-1710607198>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AUMR7HYYXTQOMAVU2VMOKADXZIHW3ANCNFSM5OVPOTSQ>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>\r\n","createdAt":"2023-09-07T18:40:39Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-1710613106","viewerDidAuthor":false},{"id":"IC_kwDODNqesM5l9fRN","author":{"login":"ShahabT"},"authorAssociation":"MEMBER","body":"@paulnpdev taskQ level. More specifically, the combination of namespace + taskQ name + taskQ type (workflow vs activity)","createdAt":"2023-09-07T18:45:13Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-1710617677","viewerDidAuthor":false},{"id":"IC_kwDODNqesM5mSm26","author":{"login":"ShahabT"},"authorAssociation":"MEMBER","body":"After deeper analysis based on synthetic and customer workloads, it turned out that:\r\n- **Sync match rarely happens in presence of a backlog.** This is because sync match request (for tasks coming directly from history) only go through if a poller is available in that very moment, they do not wait and compete with the pending backlog task for new pollers to become available.\r\n- **Task queue partitioning is the main reason for dispatch order mixups.** Due to the asymmetricity of our root vs leaf partitions, when there is a backlog, the root partition tends to process it's backlog much faster and the leaf partitions accumulate heavier/older backlogs. [I'm investigating how/why this happens]\r\n\r\nGood News\r\n-----------\r\nFor task queues with low/medium load (in terms of tasks per sec) where a single task queue partition can do all the work **you can get approximate FIFO ordering by reducing the number of partitions to 1**. The following dynamic configs should be used for that:\r\n```\r\nmatching.numTaskqueueWritePartitions:\r\n  - value: 1\r\n    constraints:\r\n      namespace: <namespace name>\r\n      taskQueueName: <task queue name>\r\nmatching.numTaskqueueReadPartitions:\r\n  - value: 1\r\n    constraints:\r\n      namespace: <namespace name>\r\n      taskQueueName: <task queue name>\r\n```\r\nNote that if you are changing this prop for a pre-exsiting task queue, `matching.numTaskqueueWritePartitions` should be reduced first, and after making sure no unfinished tasks are in the old partitions, you can update `matching.numTaskqueueReadPartitions` too.","createdAt":"2023-09-12T17:35:50Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-1716153786","viewerDidAuthor":false},{"id":"IC_kwDODNqesM6ErVLe","author":{"login":"awartoft"},"authorAssociation":"NONE","body":"@ShahabT How do we do this in the temporal cloud?","createdAt":"2024-07-12T16:46:09Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-2225951454","viewerDidAuthor":false},{"id":"IC_kwDODNqesM6Er87r","author":{"login":"paulnpdev"},"authorAssociation":"MEMBER","body":"   - *Sync match rarely happens in presence of a backlog.* This is because\r\n   sync match request (for tasks coming directly from history) only go through\r\n   if a poller is available in that very moment, they do not wait and compete\r\n   with the pending backlog task for new pollers to become available.\r\n\r\nIs this something we want to try to fix?  It bothers me that we become\r\nsignificantly less efficient when we're processing backlog.  Maybe we\r\nreserve some of the dispatch capacity for fulfilling sync match and some\r\nfor processing backlog?  Of course it's not that easy, but conceptually?\r\n\r\n\r\nOn Tue, Sep 12, 2023 at 10:36 AM Shahab Tajik ***@***.***>\r\nwrote:\r\n\r\n> After deeper analysis based on synthetic and customer workloads, it turned\r\n> out that:\r\n>\r\n>    - *Sync match rarely happens in presence of a backlog.* This is\r\n>    because sync match request (for tasks coming directly from history) only go\r\n>    through if a poller is available in that very moment, they do not wait and\r\n>    compete with the pending backlog task for new pollers to become available.\r\n>    - *Task queue partitioning is the main reason for dispatch order\r\n>    mixups.* Due to the asymmetricity of our root vs leaf partitions, when\r\n>    there is a backlog, the root partition tends to process it's backlog much\r\n>    faster and the leaf partitions accumulate heavier/older backlogs. [I'm\r\n>    investigating how/why this happens]\r\n>\r\n> Good News\r\n>\r\n> For task queues with low/medium load (in terms of tasks per sec) where a\r\n> single task queue partition can do all the work *you can get approximate\r\n> FIFO ordering by reducing the number of partitions to 1*. The following\r\n> dynamic configs should be used for that:\r\n>\r\n> matching.numTaskqueueWritePartitions:\r\n>   - value: 1\r\n>     constraints:\r\n>       namespace: <namespace name>\r\n>       taskQueueName: <task queue name>\r\n> matching.numTaskqueueReadPartitions:\r\n>   - value: 1\r\n>     constraints:\r\n>       namespace: <namespace name>\r\n>       taskQueueName: <task queue name>\r\n>\r\n> Note that if you are changing this prop for a pre-exsiting task queue,\r\n> matching.numTaskqueueWritePartitions should be reduced first, and after\r\n> making sure no unfinished tasks are in the old partitions, you can update\r\n> matching.numTaskqueueReadPartitions too.\r\n>\r\n> —\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/temporalio/temporal/issues/2517#issuecomment-1716153786>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AUMR7H244NADJG2RISXT5PTX2CMQDANCNFSM5OVPOTSQ>\r\n> .\r\n> You are receiving this because you were mentioned.Message ID:\r\n> ***@***.***>\r\n>\r\n","createdAt":"2024-07-12T18:04:09Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-2226114283","viewerDidAuthor":false},{"id":"IC_kwDODNqesM7b7TZH","author":{"login":"kshitij-g"},"authorAssociation":"NONE","body":"Is there any update on this issue?","createdAt":"2025-12-24T13:09:43Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-3689756231","viewerDidAuthor":false},{"id":"IC_kwDODNqesM7cmZ8Z","author":{"login":"ShahabT"},"authorAssociation":"MEMBER","body":"@awartoft in Cloud you can create a ticket and ask support to set the number of partitions to your (low traffic) task queue to 1 so you can benefit from the fifo behavior.\n\n@paulnpdev I agree that if the sync-match task belongs to high a high priority or a fairness key that should not be backlogged (or has tiny backlog), we should avoid DB write/read. I believe @dnr has optimization ideas here.\n\n@kshitij-g there is no further update here, I consider this issue completed and closing it now. \n\nTLDR: as of now, we provide exact FIFO for small task queues (single-partition) and for larger ones the behavior is FIFOish because by design, the backlog in partitions remain pretty balanced.\n\n(in the future, partitioning will be more dynamic and changing number of partitions may bring unbalances, but we might add more coordination between partitions in that case to preserve FIFOish-ness, TBD)","createdAt":"2025-12-31T01:29:57Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/temporal/issues/2517#issuecomment-3701055257","viewerDidAuthor":false}],"createdAt":"2022-02-17T18:23:10Z","labels":[{"id":"MDU6TGFiZWwxNjIxMDMwNzg3","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"milestone":null,"number":2517,"reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":7}}],"state":"CLOSED","title":"Make task queues more ordered","updatedAt":"2025-12-31T01:30:00Z","url":"https://github.com/temporalio/temporal/issues/2517"}
