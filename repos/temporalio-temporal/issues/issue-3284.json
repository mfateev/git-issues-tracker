{"assignees":[],"author":{"id":"MDQ6VXNlcjUzMjEwOA==","is_bot":false,"login":"Spikhalskiy","name":"Dmitry Spikhalsky"},"body":"## Expected Behavior\r\n\r\nIf a worker reports an unexpected sequence of commands, a worker should get a gRPC error like this: \r\n\r\n> io.grpc.StatusRuntimeException: INVALID_ARGUMENT: invalid command sequence: [<sequence>], command CompleteWorkflowExecution must be the last command.\r\n\r\nirrespectively of the size of the number of commands that were sent. \r\n\r\nThe server should return an error message that is aligned with the announced receiver limit or at least under the default gRPC-over-HTTP/2 header limit.\r\n\r\n## Actual Behavior\r\n\r\nReproduction:\r\nhttps://github.com/Spikhalskiy/java-sdk/commit/74e6e3f2af363afd061cd9ec9f2c0d9b31ea5b21#diff-e566b269374183dd0f8a9068200b3c417dff37dce93f64021fe8cd40e71dee21R80\r\n\r\nThis reproduction generates a large (but manageable and under all the gRPC limits) and incorrect sequence of commands on the workflow task completion\r\n[CompleteWorkflowExecution, RecordMarker \\<xManyTimes\\>]\r\nThe worker receives `RST_STREAM` frame instead of the normal server response and gets a connection closed.\r\n`io.grpc.StatusRuntimeException: INTERNAL: RST_STREAM closed stream. HTTP/2 error code: INTERNAL_ERROR`.\r\nAnother manifestation of this problem on smaller sizes is\r\n`io.grpc.netty.shaded.io.netty.handler.codec.http2.Http2Exception$HeaderListSizeException: Header size exceeded max allowed size (10240)`\r\nThis leads to a cryptic log and there is no way for an application developer to understand that it's an incorrect sequence of commands causing it.\r\n\r\n## Workaround\r\n\r\nClient-side can temporary set a large limit on incoming headers (maxInboundMetadataSize) like it's shown here:\r\nhttps://github.com/Spikhalskiy/java-sdk/commit/74e6e3f2af363afd061cd9ec9f2c0d9b31ea5b21#diff-dbd68ad479d675fe5c67f7fe0141d1078d9009fb27f6cd52e5ed6c42bf10d46aR179\r\n\r\n## Root cause analysis\r\n\r\nThe server uses a raw sequence of commands as a part of the error message. The server doesn't respect either the SDK settings of maxInboundMetadataSize (that should be announced in the `SETTINGS_MAX_HEADER_LIST_SIZE` field of `SETTINGS` HTTP/2 frame) or a standard HTTP/2 limit for headers of [8192 bytes](https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md).\r\n\r\n## Proposed solution\r\n\r\nThe Server should preprocess all the variable-sized portions of error messages to make sure that it fits into\r\n- a header limit announced by the counterpart (better)\r\n- some reasonable default max length that is lower than the default gRPC metadata limit of 8Kb (acceptable)\r\n\r\nIt's better to receive an error message without specific commands or with a trimmed list than to get a broken connection and no useful error message at all\r\n\r\n## Related HTTP/2 specs\r\n\r\n> [6.5.2](https://datatracker.ietf.org/doc/html/rfc7540#section-6.5.2).  Defined SETTINGS Parameters\r\n>    SETTINGS_MAX_HEADER_LIST_SIZE (0x6):  This advisory setting informs a\r\n>       peer of the maximum size of header list that the sender is\r\n>       prepared to accept, in octets.  The value is based on the\r\n>       uncompressed size of header fields, including the length of the\r\n>       name and value in octets plus an overhead of 32 octets for each\r\n>       header field.\r\n> \r\n>       For any given request, a lower limit than what is advertised MAY\r\n>       be enforced.  The initial value of this setting is unlimited.\r\n\r\n\r\n> [10.5.1](https://datatracker.ietf.org/doc/html/rfc7540#section-10.5.1).  Limits on Header Block Size\r\n> \r\n>    A large header block ([Section 4.3](https://datatracker.ietf.org/doc/html/rfc7540#section-4.3)) can cause an implementation to\r\n>    commit a large amount of state.  Header fields that are critical for\r\n>    routing can appear toward the end of a header block, which prevents\r\n>    streaming of header fields to their ultimate destination.  This\r\n>    ordering and other reasons, such as ensuring cache correctness, mean\r\n>    that an endpoint might need to buffer the entire header block.  Since\r\n>    there is no hard limit to the size of a header block, some endpoints\r\n>    could be forced to commit a large amount of available memory for\r\n>    header fields.\r\n> \r\n>    An endpoint can use the SETTINGS_MAX_HEADER_LIST_SIZE to advise peers\r\n>    of limits that might apply on the size of header blocks.  This\r\n>    setting is only advisory, so endpoints MAY choose to send header\r\n>    blocks that exceed this limit and risk having the request or response\r\n>    being treated as malformed.  This setting is specific to a\r\n>    connection, so any request or response could encounter a hop with a\r\n>    lower, unknown limit.  An intermediary can attempt to avoid this\r\n>    problem by passing on values presented by different peers, but they\r\n>    are not obligated to do so.\r\n> \r\n>    A server that receives a larger header block than it is willing to\r\n>    handle can send an HTTP 431 (Request Header Fields Too Large) status\r\n>    code [[RFC6585](https://datatracker.ietf.org/doc/html/rfc6585)].  A client can discard responses that it cannot\r\n>    process.  The header block MUST be processed to ensure a consistent\r\n>    connection state, unless the connection is closed.\r\n","closedAt":null,"comments":[],"createdAt":"2022-08-30T18:54:12Z","labels":[{"id":"MDU6TGFiZWwxNjIxMDMwNzg0","name":"bug","description":"Something isn't working","color":"d73a4a"}],"milestone":null,"number":3284,"reactionGroups":[],"state":"OPEN","title":"Server returns status messages over metadata limit leading to connection drops and cryptic errors","updatedAt":"2023-03-30T20:29:22Z","url":"https://github.com/temporalio/temporal/issues/3284"}
