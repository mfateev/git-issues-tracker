{"assignees":[],"author":{"id":"MDQ6VXNlcjkwMTcxMg==","is_bot":false,"login":"thewmo","name":""},"body":"## Expected Behavior\r\n\r\nIf the Temporal front-end server is behind a load balancer, and that load balancer should close an idle connection that is polling for tasks, if anything is logged it should be at a debug or info level, and the SDK should immediately create a new connection to resume the poll.\r\n\r\n## Actual Behavior\r\n\r\nsdk-java logs the following exception at level ERROR:\r\n\r\n`io.grpc.StatusRuntimeException: UNAVAILABLE: unavailable\\n\tat io.grpc.stub.ClientCalls.toStatusRuntimeException(ClientCalls.java:262) ~[grpc-stub-1.39.0.jar!/:1.39.0\r\nat io.grpc.stub.ClientCalls.getUnchecked(ClientCalls.java:243) ~[grpc-stub-1.39.0.jar!/:1.39.0\r\nat io.grpc.stub.ClientCalls.blockingUnaryCall(ClientCalls.java:156) ~[grpc-stub-1.39.0.jar!/:1.39.0`\r\n\r\nThese clutter the logs and the only way to squelch them is to basically turn off all logging from the Poller logger. I have observed no functionality problems with this application, and the Poller appears to immediately resume a poll after this happens, so I don't think there are any functional problems here beyond the log spam.\r\n\r\n## Steps to Reproduce the Problem\r\n\r\nThese steps correspond to the configuration in which I am observing the issue.\r\n\r\n  1. Deploy temporal in AWS, in my case it is on ECS using the all-in-one docker image but the deployment method shouldn't matter.\r\n  2. Configure an AWS ALB with http/2 GRPC support enabled pointing at the Temporal front-end endpoint. Set the idle-timeout of the ALB to some specific value in the range of several minutes.\r\n  3. Deploy a java application using sdk-java using the AWS ALB as the target. Create at least one worker.\r\n  4. Observe that polling for tasks logs these exceptions, and the frequency of the exceptions scales inversely with the value of the ALB idle-timeout.\r\n\r\n## Specifications\r\n\r\n  - Version: 1.1.0\r\n  - Platform: Java 11\r\n\r\nNote that I debugged into the exceptions and can observe them coming out of the GRPC layer and bubbling up to the Poller's error handler, which is treating all errors in the same manner. Probably this error could be recognized as harmless and logged at a lower logging level?\r\n","closedAt":"2023-12-27T01:10:54Z","comments":[{"id":"IC_kwDODN12PM427XFu","author":{"login":"vitarb"},"authorAssociation":"CONTRIBUTOR","body":"I've tried to reproduce this and the only exception that I see logged is at WARN level from the [grpc retrier](https://github.com/temporalio/sdk-java/blob/0da3149c8eb16454c30fb7bda32d28f2539f3f3c/temporal-serviceclient/src/main/java/io/temporal/internal/retryer/GrpcSyncRetryer.java#L56). I don't see anything logged at the ERROR level.\r\nI think that WARN level is too high and we should change it to DEBUG, since these errors can happen pretty rapidly (at the request level) and we should log only actual failures after we run out of retries at INFO+ level.","createdAt":"2021-09-17T06:19:46Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-java/issues/618#issuecomment-921530734","viewerDidAuthor":false},{"id":"IC_kwDODN12PM429g7o","author":{"login":"vitarb"},"authorAssociation":"CONTRIBUTOR","body":"I made a change that allows making log level for rpc retries configurable, but I don't like this approach as it restricts us to a single level in the entire retry layer, so we are not going to land this change. Instead I'm going to adjust the default log level from WARN to DEBUG for they sync retrier.","createdAt":"2021-09-17T21:36:48Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/temporalio/sdk-java/issues/618#issuecomment-922095336","viewerDidAuthor":false},{"id":"IC_kwDODN12PM442rX0","author":{"login":"bergundy"},"authorAssociation":"MEMBER","body":"@Spikhalskiy please triage","createdAt":"2021-10-28T13:42:09Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-java/issues/618#issuecomment-953857524","viewerDidAuthor":false},{"id":"IC_kwDODN12PM5vc7pV","author":{"login":"josh-berry"},"authorAssociation":"NONE","body":"Should already be addressed as part of other work; closing.","createdAt":"2023-12-27T01:10:54Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-java/issues/618#issuecomment-1869855317","viewerDidAuthor":false}],"createdAt":"2021-08-04T14:58:47Z","labels":[],"milestone":null,"number":618,"reactionGroups":[],"state":"CLOSED","title":"a load balancer with an idle timeout causes java sdk to log UNAVAILABLE errors","updatedAt":"2023-12-27T01:10:54Z","url":"https://github.com/temporalio/sdk-java/issues/618"}
