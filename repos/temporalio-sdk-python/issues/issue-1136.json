{"assignees":[],"author":{"id":"MDQ6VXNlcjQxMTI1MjMw","is_bot":false,"login":"databill86","name":""},"body":"**Context:** This issue was separated from a [previous bug report](https://github.com/temporalio/sdk-python/issues/1134). @tconley1428 confirmed that the plugin approach is the only way to run agents [edit: Tim - Agents SDK agents] in Temporal workflows, but the tracing/observability issue remains unresolved and I think it deserves a separate issue.\n\n### What are you really trying to do?\n\nI'm building a multi-tenant application using Temporal workflows with OpenAI agents and need observability/tracing to work properly with Langfuse (though logfire, as explained [here](https://langfuse.com/integrations/frameworks/openai-agents)). I want to trace agent execution, tool calls, and model interactions through Langfuse and logfire.\n\n### Describe the bug\n\nWhen using Temporal workflows with OpenAI agents and the required `OpenAIAgentsPlugin`, the Langfuse tracing instrumentation fails to work properly. The tracing setup doesn't capture agent execution traces in Langfuse.\n\n**Expected Behavior:**\n- Agent execution should be traced and visible in Langfuse.\n\n<img width=\"1638\" height=\"288\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/2fdfdaca-4d31-4ad3-8d58-b64f26245f9b\" />\n\n**Current Behavior:**\n- No traces appear in Langfuse when using the plugin approach\n- Agent execution happens but is not observable through Langfuse\n- Tracing works fine when running agents outside of Temporal workflows\n\n### Minimal Reproduction\n\n**1. Tracing Setup (that works outside workflows):**\n```python\nfrom agents import set_trace_processors\nimport logfire\nimport nest_asyncio\nimport os\n\ndef init_tracing():\n    \"\"\"Initialize tracing and observability.\"\"\"\n    # Set Langfuse env vars from settings\n    os.environ.setdefault(\"LANGFUSE_PUBLIC_KEY\", LANGFUSE_PUBLIC_KEY)\n    os.environ.setdefault(\"LANGFUSE_SECRET_KEY\", LANGFUSE_SECRET_KEY)\n    os.environ.setdefault(\"LANGFUSE_HOST\", LANGFUSE_HOST)\n\n    set_trace_processors([])  # only disable OpenAI tracing\n\n    # Instrument OpenAI Agents SDK via pydantic-ai logfire\n    try:\n        nest_asyncio.apply()\n        logfire.configure(service_name=\"temporal-demo\", send_to_logfire=False)\n        # This method automatically patches the OpenAI Agents SDK to send logs via OTLP to Langfuse.\n        logfire.instrument_openai_agents()\n    except Exception as exc:\n        logger.error(f\"Logfire instrumentation not available: {exc}\")\n```\n\n**2. Worker Setup with Plugin (required for Temporal workflows):**\n```python\nfrom temporalio.worker import Worker\nfrom temporalio.contrib.openai_agents import OpenAIAgentsPlugin, ModelActivityParameters\nfrom datetime import timedelta\n\nasync def main():\n    # Initialize tracing (conflicts with plugins)\n    init_tracing()  # Sets up logfire ‚Üí OTLP ‚Üí Langfuse\n    \n    # Create Temporal client with plugins (required for agents)\n    plugins = [\n        OpenAIAgentsPlugin(\n            model_params=ModelActivityParameters(\n                start_to_close_timeout=timedelta(seconds=30)\n            ),\n            model_provider=CustomLitellmProvider(\n                base_url=PROXY_BASE_URL,\n                api_key=PROXY_API_KEY,\n            ),\n        ),\n    ]\n    \n    client = await create_temporal_client(include_plugins=True)\n    \n    # Run the worker\n    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as activity_executor:\n        worker = Worker(\n            client,\n            task_queue=\"demo-task-queue\",\n            workflows=[MyWorkflow],\n            activities=[simple_tool_activity],\n            activity_executor=activity_executor,\n        )\n        await worker.run()\n```\n\n**3. Workflow with Agent:**\n```python\nfrom temporalio import workflow\nfrom agents import Agent\n\n@workflow.defn\nclass MyWorkflow:\n    @workflow.run\n    async def run(self) -> str:\n        # Create agent with string model (required with plugins)\n        agent = Agent(\n            name=\"Triage Agent\",\n            instructions=\"Your instructions here\",\n            model=\"gpt-4o-mini\",  # String model name required with plugins\n            tools=tools,\n        )\n        \n        # This executes but doesn't appear in Langfuse traces\n        result = await agent.run(\"Your message here\")\n        return result\n```\n\n**4. Custom Model Provider (for proxy configuration):**\n\n```python\nfrom agents.extensions.models.litellm_model import LitellmModel\nfrom agents.models.interface import Model, ModelProvider\n\nclass CustomLitellmProvider(ModelProvider):\n    \"\"\"Custom ModelProvider that uses LiteLLM with configurable base_url and api_key.\"\"\"\n\n    def __init__(self, base_url: str | None = None, api_key: str | None = None):\n        self.base_url = base_url\n        self.api_key = api_key\n\n    @property\n    def model_class(self) -> type[Model]:\n        return LitellmModel\n\n    @property\n    def provider_name(self) -> str:\n        return \"CustomLitellmProvider\"\n\n    def get_model(self, model_name: str) -> Model:\n        return LitellmModel(\n            model=model_name,\n            base_url=self.base_url,\n            api_key=self.api_key,\n        )\n```\n\n### Environment/Versions\n\n- OS and processor: Linux\n- Temporal Version: temporalio==1.18.0\n- OpenAI SDK: openai==1.109.0\n- OpenAI Agents: openai-agents==0.3.2\n- Python: 3.11\n- Langfuse: Latest version\n- logfire: Latest version\n- Are you using Docker or Kubernetes or building Temporal from source? Using Docker\n\n\n**Current Behavior:**\nNo traces appear in Langfuse at all when using the plugin approach.\n\n\nThanks üôè\n","closedAt":null,"comments":[{"id":"IC_kwDOGusT1c7H15MG","author":{"login":"tconley1428"},"authorAssociation":"MEMBER","body":"Can you clarify, the link you provided doesn't mention logfire at all.","createdAt":"2025-09-30T15:39:35Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-python/issues/1136#issuecomment-3352793862","viewerDidAuthor":false},{"id":"IC_kwDOGusT1c7H2OZH","author":{"login":"databill86"},"authorAssociation":"NONE","body":"Sorry about that, I actually had the link saved in a readme file and copy pasted without checking. The tutorial has been updated, and it no longer uses [logfire instrument](https://logfire.pydantic.dev/docs/integrations/llms/openai/#openai-agents). \n\nInstead of `logfire.instrument_openai_agents()`, they now recommend:\n```python\nfrom openinference.instrumentation.openai_agents import OpenAIAgentsInstrumentor\nOpenAIAgentsInstrumentor().instrument()\n```\n\nI tested this, and it worked! I can see the traces in Langfuse (screenshot attached).\n\n<img width=\"1896\" height=\"831\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/85ec8346-9af8-463d-9c5c-efa1956af564\" />\n\nHowever, I have the following errors in the logs:\n\n```\nERROR:opentelemetry.context:Failed to detach context\nTraceback (most recent call last):\n  File \"/lib/python3.11/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n    _RUNTIME_CONTEXT.detach(token)\n  File \"/lib/python3.11/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n    self._current_context.reset(token)\nValueError: <Token var=<ContextVar name='current_context' default={} at 0x79c8f92d40e0> at 0x79c8c81a70c0> was created in a different Context\n\n2025-09-30 17:53:03.498 | INFO     | activities.simple_tool_activity:tool_func:27 - ‚úÖ Tool activity completed: Tool processed: 'Hello, this is a test message for the demo!' - This is a simple response from the tool activity!\n\nERROR:opentelemetry.context:Failed to detach context\nTraceback (most recent call last):\n  File \"/lib/python3.11/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n    _RUNTIME_CONTEXT.detach(token)\n  File \"/lib/python3.11/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n    self._current_context.reset(token)\nValueError: <Token var=<ContextVar name='current_context' default={} at 0x79c8f92d40e0> at 0x79c8b81d9b40> was created in a different Context\nERROR:opentelemetry.context:Failed to detach context\nTraceback (most recent call last):\n  File \"/lib/python3.11/site-packages/opentelemetry/context/__init__.py\", line 155, in detach\n    _RUNTIME_CONTEXT.detach(token)\n  File \"/lib/python3.11/site-packages/opentelemetry/context/contextvars_context.py\", line 53, in detach\n    self._current_context.reset(token)\nValueError: <Token var=<ContextVar name='current_context' default={} at 0x79c8f92d40e0> at 0x79c8c81a47c0> was created in a different Context\n```\nShould I be concerned about these context detachment errors?\n\n","createdAt":"2025-09-30T16:04:19Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-python/issues/1136#issuecomment-3352880711","viewerDidAuthor":false},{"id":"IC_kwDOGusT1c7H2Y0T","author":{"login":"tconley1428"},"authorAssociation":"MEMBER","body":"We have an open report of that which has been around for a while. https://github.com/temporalio/sdk-python/issues/441\nIf you don't see other issues with the run, it is probably okay to carry on, but it is something that is bubbling up for us to prioritize investigating. ","createdAt":"2025-09-30T16:17:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-python/issues/1136#issuecomment-3352923411","viewerDidAuthor":false},{"id":"IC_kwDOGusT1c7H_gzb","author":{"login":"databill86"},"authorAssociation":"NONE","body":"\nThanks for the quick response.\n\n**Tracing is absolutely critical for us**, we can't avoid it. The specific tracing tool doesn't matter as long as it works reliably with Temporal. Langfuse is probably the most widely used, so if there's something that works well with that, it would be cool.\n\nTo summarize, I've done a lot of testing with different tracing approaches and here's what I found:\n\n1. Using [logfire](https://logfire.pydantic.dev/docs/integrations/llms/openai/#openai-agents) with **`logfire.instrument_openai_agents()`** \n   - ‚ùå **Doesn't work with Temporal (when using plugins in the client definition)** - nothing gets traced, no errors\n   - ‚úÖ **Works without Temporal plugins** - traces perfectly when agent runs in a regular activity outside workflow\n\n2. Using [logfire](https://logfire.pydantic.dev/docs/integrations/llms/openai/#openai-agents) with **`logfire.instrument_openai()`** (global OpenAI client instrumentation)\n   - ‚ö†Ô∏è **Partially works with Temporal (when using plugins in the client definition)** - traces metadata but input/output are null, also we have multiple observations in different langfuse traces for the same agent run, without any errors.\n\n3. Using [openinference](https://langfuse.com/integrations/frameworks/openai-agents) **`OpenAIAgentsInstrumentor().instrument()`** \n`from openinference.instrumentation.openai_agents import OpenAIAgentsInstrumentor\nOpenAIAgentsInstrumentor().instrument()`\n   - ‚ö†Ô∏è **Works but with context detachment errors**\n   - Traces content but throws context-related errors\n\nThanks again for looking into this! üôè\n","createdAt":"2025-10-01T08:37:28Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-python/issues/1136#issuecomment-3355315419","viewerDidAuthor":false},{"id":"IC_kwDOGusT1c7IHHNC","author":{"login":"tconley1428"},"authorAssociation":"MEMBER","body":"1. I looked into why logfire doesn't work. Their instrumentation overrides the TracingProvider, which is also what we do to enable tracing and these conflict. I found a way to combine the two, but that doesn't help, as logfire's implementation is not durable safe. \n\n2. Wouldn't be expected to work well really, since the agents instrumentor exists to better instrument the scenario, versus doing so directly through the openai client library.\n\n3. We have the context detachment errors on the docket to look at.","createdAt":"2025-10-01T17:04:00Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/temporalio/sdk-python/issues/1136#issuecomment-3357307714","viewerDidAuthor":false}],"createdAt":"2025-09-30T15:25:56Z","labels":[{"id":"LA_kwDOGusT1c7gQgHK","name":"bug","description":"Something isn't working","color":"d73a4a"}],"milestone":null,"number":1136,"reactionGroups":[],"state":"OPEN","title":"[Bug] Langfuse Tracing Not Working with Temporal OpenAI Agents Plugin","updatedAt":"2025-12-02T17:34:19Z","url":"https://github.com/temporalio/sdk-python/issues/1136"}
