{"assignees":[],"author":{"id":"MDQ6VXNlcjk1NTk2NTU=","is_bot":false,"login":"gregbrowndev","name":"Greg Brown"},"body":"### Is your feature request related to a problem? Please describe.\r\n\r\n<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->\r\n\r\nMy application is a batch-oriented ETL pipeline. There are different async activities that interact with a different third-party API throughout the workflow. For example, the `geocoding` activity uses Google Places API, another activity might use the OpenAI API, etc.\r\n\r\nEach activity is subject to external rate limits. \r\n\r\nWhile I can control rate limiting within my code, I can't easily control the concurrency of activities executed by the worker. This means when multiple activities of the same type are running, they are in contention for the rate limit, and simply take longer to finish or worse the activity can end up timing out due to the global throttling. \r\n\r\nMy solution so far has been to deploy a separate worker for each activity and set the `max_concurrent_activities` worker option to control the concurrency and allow one or two activities to complete as quick as possible. However, this has created a lot of DevOps overhead and it can be hard for people on the team to set the worker up correctly when they add a new activity that has a rate limit.\r\n\r\n\r\n### Describe the solution you'd like\r\n\r\n<!-- A clear and concise description of what you want to happen. SCREENSHOTS OR CODE SAMPLES ARE VERY HELPFUL -->\r\n\r\nI saw the experimental `WorkerTuner` option added in this PR: https://github.com/temporalio/sdk-python/pull/559.\r\n\r\nIt would be great for this to support tuning for specific activities, e.g. defining the number of slots for a given activity name. This would allow a single async worker to handle all of my activities but only let a controllable number of each type run at any given time.\r\n\r\n\r\n### Additional context\r\n\r\n<!-- Add any other context or screenshots about the feature request here. -->\r\n\r\nI saw there is a Go- (and Java I think) based example for creating a [Mutex Workflow](https://github.com/temporalio/samples-go/blob/main/mutex/mutex_workflow.go) that could control concurrency globally. This might be a better overall solution, but I struggled to apply this pattern in Python. I wouldn't expect the worker tuning to prevent contention if you scaled out the number of workers. However, in my solution, I have specifically disabled autoscaling on this worker for this reason, so controlling this at the worker level would be a lot more simple. ","closedAt":"2024-10-09T14:45:42Z","comments":[{"id":"IC_kwDOGusT1c6PMll3","author":{"login":"cretz"},"authorAssociation":"MEMBER","body":"This will not work with how slots are used. You should use separate task queues if you need separate tuning options.\r\n\r\nA slot is a reserved spot to request work from a _task queue_ from the server (and if no slot available, we don't ask for work). The activity name is not known at slot reservation time. Granted when we expand the slot supplier interface in Python to allow custom implementations, you can use the existing scheduled activities to help you derive the next slot reservation, but it will still always be per _task queue_ because Temporal distributes work to workers at the task queue level not the activity name level.","createdAt":"2024-10-09T14:03:14Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/temporalio/sdk-python/issues/663#issuecomment-2402441591","viewerDidAuthor":false},{"id":"IC_kwDOGusT1c6PMtFU","author":{"login":"gregbrowndev"},"authorAssociation":"NONE","body":"Thanks, @cretz that does make sense. \r\n\r\nI think then the only other option is the mutex workflow (at least if I understand it). Basically, I just need to avoid scheduling an activity altogether if there's already a given number of them executing already.\r\n\r\nIf I have a workflow and the next activity to schedule is `geocoding`, I assume the mutex workflow would allow me to simply make the calling workflow wait until the resource can be acquired before it can schedule it. \r\n\r\nI can't allow the workflow to schedule the activity and make the activity wait on a semaphore because it would eventually timeout if 100s of these activities were scheduled during a short period. \r\n\r\nHappy for you to close the issue ðŸ‘ðŸ» ","createdAt":"2024-10-09T14:15:03Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-python/issues/663#issuecomment-2402472276","viewerDidAuthor":false},{"id":"IC_kwDOGusT1c6PNATg","author":{"login":"cretz"},"authorAssociation":"MEMBER","body":"> I think then the only other option is the mutex workflow\r\n\r\nI think you should use separate task queues (i.e. separate workers) for activities that need to have their concurrency limited separately. This is a very common approach.\r\n\r\nGranted the only global setting is max task queue concurrent activities there, so yes a mutex workflow may work best for global, but note it would not support high-throughput rate limiting.","createdAt":"2024-10-09T14:45:42Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/temporalio/sdk-python/issues/663#issuecomment-2402551008","viewerDidAuthor":false}],"createdAt":"2024-10-09T13:57:04Z","labels":[{"id":"LA_kwDOGusT1c7gQgHN","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"milestone":null,"number":663,"reactionGroups":[],"state":"CLOSED","title":"[Feature Request] Activity specific worker tuning","updatedAt":"2024-10-09T14:46:42Z","url":"https://github.com/temporalio/sdk-python/issues/663"}
