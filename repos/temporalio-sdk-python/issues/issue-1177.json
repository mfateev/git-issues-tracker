{"assignees":[],"author":{"id":"U_kgDOBZL86w","is_bot":false,"login":"morgan-cromell","name":"Morgan Cromell"},"body":"### What are you really trying to do?\n\n<!-- \nTell us at a high level what you're doing, to avoid XY problem (https://en.wikipedia.org/wiki/XY_problem) \n-->\n\nUsing the openai agent sdk with temporal and LiteLLM with aws bedrock. For example the anthropic models.\n\n### Describe the bug\n\n<!-- A clear and concise description of what the bug is. -->\n\n<!-- If applicable, add screenshots or code blocks to help explain your problem. You can also use [Loom](http://loom.com/) to do short, free video bug reports. -->\n\nWhen you get rate limited by aws bedrock it throws an  `litellm.exceptions.ServiceUnavailableError`\n\nFor example: \n`litellm.ServiceUnavailableError: BedrockException - {\"message\":\"Model is getting throttled. Try your request again.\"}`\n\nThis is a retryable error and should produce a retry of the activity. Instead it results in this error\n`temporalio.exceptions.ApplicationError: Non retryable OpenAI status code`\n\n### Minimal Reproduction\n\n<!-- \nModify our hello world templates to demonstrate:\n\n- TypeScript: https://github.com/temporalio/samples-typescript/tree/main/hello-world\n- Go: https://github.com/temporalio/money-transfer-project-template-go\n- Java: https://github.com/temporalio/money-transfer-project-template-java\n- PHP: https://github.com/temporalio/samples-php#samples\n-->\n\nSetup one of the openAI agent SDK temporal samples and use the LiteLLM provider. Use one of the models that has a lot of throttling and wait until you get throttled/rate limited.\n\n### Environment/Versions\n\n<!-- Please complete the following information where relevant. -->\n\n- OS and processor: [e.g. M1 Mac, x86 Windows, Linux]\n- Temporal Version: [e.g. 1.14.0?] and/or SDK version\n- Are you using Docker or Kubernetes or building Temporal from source?\nTemporal python sdk 1.18.1\n### Additional context\n\n<!-- Add any other context about the problem here. -->\n","closedAt":"2025-10-27T14:19:04Z","comments":[{"id":"IC_kwDOGusT1c7MpJAI","author":{"login":"tconley1428"},"authorAssociation":"MEMBER","body":"We tried to mimic the retry policies implemented by OpenAI. https://github.com/openai/openai-python/blob/dff16b5e9964bf85157eb41181255ed5dde8dda4/src/openai/_base_client.py#L750. In this particular case, given that the error did not provide retry headers, we base it on the status code reported by the underlying provider. LiteLLM is turning it into https://github.com/BerriAI/litellm/blob/57a2ec3beb7fcfb7ec7ccd379a19d2db951da9ef/litellm/exceptions.py#L485 which has a status code of 503. We could theoretically change our retry behavior on that, but I'm wary of creating that discrepancy, since the same retry logic is used for litellm and openai. \n\nIt does seem like LiteLLM's throttling error detection is either incorrect or insufficient for bedrock: https://github.com/BerriAI/litellm/blob/57a2ec3beb7fcfb7ec7ccd379a19d2db951da9ef/litellm/litellm_core_utils/exception_mapping_utils.py#L942, which is something you could report to them. If it was converted to a `429`, retry would happen.\n\nI think the more likely thing for us to do would be to add an additional configuration point to let you do your own exception handling for your particular needs. ","createdAt":"2025-10-22T16:58:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-python/issues/1177#issuecomment-3433336840","viewerDidAuthor":false},{"id":"IC_kwDOGusT1c7MzlfF","author":{"login":"morgan-cromell"},"authorAssociation":"NONE","body":"@tconley1428 your implementation does not correctly mimic the openAI retry policies. You only retry on 500 errors while the openAI code retries on >= 500\nhttps://github.com/openai/openai-python/blob/dff16b5e9964bf85157eb41181255ed5dde8dda4/src/openai/_base_client.py#L778\n```\n        # Retry internal errors.\n        if response.status_code >= 500:\n            log.debug(\"Retrying due to status code %i\", response.status_code)\n            return True\n```","createdAt":"2025-10-23T09:54:56Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-python/issues/1177#issuecomment-3436074949","viewerDidAuthor":false},{"id":"IC_kwDOGusT1c7M4sbs","author":{"login":"tconley1428"},"authorAssociation":"MEMBER","body":"Ah, thank you. I definitely missed the inequality comparison there. That's a straightforward fix then.","createdAt":"2025-10-23T14:43:08Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/temporalio/sdk-python/issues/1177#issuecomment-3437414124","viewerDidAuthor":false}],"createdAt":"2025-10-22T08:04:47Z","labels":[{"id":"LA_kwDOGusT1c7gQgHK","name":"bug","description":"Something isn't working","color":"d73a4a"}],"milestone":null,"number":1177,"reactionGroups":[],"state":"CLOSED","title":"[Bug] OpenAI agent sdk non retryable error on liteLLM 503","updatedAt":"2025-10-27T14:19:04Z","url":"https://github.com/temporalio/sdk-python/issues/1177"}
