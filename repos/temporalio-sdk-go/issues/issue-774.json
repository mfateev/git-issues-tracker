{"assignees":[],"author":{"is_bot":true,"login":"app/"},"body":"## Expected Behavior\r\n\r\nWhen querying a workflow, the worker should add the workflow to the internal cache.\r\n\r\n## Actual Behavior\r\n\r\nWhen the Worker starts and the first interaction with the workflow is a Query, the workflow is not cached, you can notice this behavior because the events are replayed from scratch every time.\r\n\r\nThe memory leak occurs because every time the query is handled, a new instance of the workflow is allocated by the worker. It only happens when the workflow stays awaiting new signals.\r\n\r\n## Steps to Reproduce the Problem\r\n\r\nConsider a workflow like\r\n\r\n```go\r\npackage workflow\r\n\r\nimport (\r\n\t\"go.temporal.io/sdk/workflow\"\r\n)\r\n\r\nfunc ReproduceML(ctx workflow.Context, param string) error {\r\n\tlog := workflow.GetLogger(ctx)\r\n\tlog.Info(\"Starting new Workflow\")\r\n\tdefer func() {\r\n\t\tlog.Info(\"Exit from workflow\")\r\n\t}()\r\n\tstate := param\r\n\tvar receivedSignals []string\r\n\r\n\terr := workflow.SetQueryHandler(ctx, \"getState\", func() (string, error) {\r\n\t\treturn state, nil\r\n\t})\r\n\r\n\tif err != nil {\r\n\t\tlog.Error(\"SetQueryHandler getState failed\", \"Error\", err)\r\n\t\treturn err\r\n\t}\r\n\r\n\tchannel := workflow.GetSignalChannel(ctx, \"ml-signals\")\r\n\tfor {\r\n\r\n\t\tif state == \"complete\" {\r\n\t\t\tbreak\r\n\t\t}\r\n\r\n\t\tvar signal string\r\n\t\t_ = channel.Receive(ctx, &signal)\r\n\t\t// Do something special with the signal and calculate the state\r\n\t\tstate = signal\r\n\r\n\t\t// Forcing memory growing, so it can be noticed it in the metrics\r\n\t\treceivedSignals = append(receivedSignals, signal)\r\n\t}\r\n\r\n\tlog.Info(\"Workflow finished\")\r\n\treturn nil\r\n}\r\n\r\n```\r\n\r\n1. Start the worker\r\n2. Create a workflow\r\n3. Signal the workflow around 500 times to generate some data.\r\n4. Restart the worker\r\n5. ONLY query the workflow several times and notice how the memory grows.\r\n\r\nVerifying:\r\n\r\n- In the logs, you can notice an entry \"Starting new Workflow\" for every query and never the \"Exit from workflow\" meaning the workflow stayed allocated.\r\n- If we disable the cache with `worker.SetStickyWorkflowCacheSize(0)`, the logs show \"Starting new Workflow\" and \"Exit from workflow\" with every query execution and the memory stops growing.\r\n- With the cache enabled, If after the 4th step, the first interaction is a signal, the \"Starting new Workflow\" is shown only once, meaning the cache was properly set, and queries to that workflow will be returned faster and the memory won't grow as before.\r\n\r\nFinal note: with a workflow with a similar structure as the above, the memory increased to 6Gb+, and without modifying code after doing one of the last two bullet points the memory stays below 30 Mb.\r\n\r\n## Specifications\r\n\r\n- Version:\r\n  go.temporal.io/sdk v1.14.0\r\n  Golang 1.17.8\r\n- Platform:\r\n  Darwin x86_64\r\n","closedAt":"2022-04-26T22:21:17Z","comments":[{"id":"IC_kwDODN1w685BYxWC","author":{"login":"cretz"},"authorAssociation":"MEMBER","body":"To confirm, for step #5, it is not reusing the cached workflow for each query call after the first one? If so, this does look like a bug and I will investigate.","createdAt":"2022-04-12T17:43:53Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-go/issues/774#issuecomment-1097012610","viewerDidAuthor":false},{"id":"IC_kwDODN1w685BY2aB","author":{"login":""},"authorAssociation":"NONE","body":"I put several breakpoints in the code, and I noticed that when the Query is executed just after the worker starts, the [putWorkflowContext](https://github.com/temporalio/sdk-go/blob/v1.14.0/internal/internal_worker_cache.go#L141) function is never called, that's why I believe the cache is not set, but if later you send a signal, the cache is set, and from there the Queries reuse it.","createdAt":"2022-04-12T18:06:29Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/temporalio/sdk-go/issues/774#issuecomment-1097033345","viewerDidAuthor":false},{"id":"IC_kwDODN1w685BdH0R","author":{"login":"cretz"},"authorAssociation":"MEMBER","body":"I am struggling to replicate this following the steps. In my tests, the workflow cache is reused. I am still doing some investigation and I'll try to provide a standalone runnable example soon.\r\n\r\n> In the logs, you can notice an entry \"Starting new Workflow\" for every query\r\n\r\nThe \"Starting new Workflow\" only logs once for me when the workflow actually started because our logger doesn't log on replay. If you're seeing \"Starting new Workflow\" every time, that means it is not treated as a replay and is actually running the workflow as new each time.","createdAt":"2022-04-13T14:55:03Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-go/issues/774#issuecomment-1098153233","viewerDidAuthor":false},{"id":"IC_kwDODN1w685BdP7_","author":{"login":"cretz"},"authorAssociation":"MEMBER","body":"Collapsed below is a standalone set of code that sends 500 signals, restarts the worker, and sends 5 queries.\r\n\r\n<details>\r\n  <summary>main.go</summary>\r\n\r\n```go\r\npackage main\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"errors\"\r\n\t\"fmt\"\r\n\t\"log\"\r\n\t\"time\"\r\n\r\n\t\"github.com/google/uuid\"\r\n\t\"github.com/uber-go/tally/v4\"\r\n\t\"go.temporal.io/api/serviceerror\"\r\n\t\"go.temporal.io/sdk/client\"\r\n\tsdktally \"go.temporal.io/sdk/contrib/tally\"\r\n\t\"go.temporal.io/sdk/worker\"\r\n\t\"go.temporal.io/sdk/workflow\"\r\n)\r\n\r\nfunc main() {\r\n\tif err := run(); err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n}\r\n\r\nfunc run() error {\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\tdefer cancel()\r\n\r\n\tlog.Printf(\"Creating client\")\r\n\tc, err := client.NewClient(client.Options{})\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed creating client: %w\", err)\r\n\t}\r\n\tdefer c.Close()\r\n\r\n\tlog.Printf(\"Starting worker 1\")\r\n\ttaskQueue := uuid.NewString()\r\n\tworker1 := worker.New(c, taskQueue, worker.Options{})\r\n\tworker1.RegisterWorkflow(SignalCountingWorkflow)\r\n\tif err := worker1.Start(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed starting worker client: %w\", err)\r\n\t}\r\n\tdefer func() {\r\n\t\tif worker1 != nil {\r\n\t\t\tworker1.Stop()\r\n\t\t}\r\n\t}()\r\n\r\n\tlog.Printf(\"Starting workflow\")\r\n\trun, err := c.ExecuteWorkflow(ctx, client.StartWorkflowOptions{TaskQueue: taskQueue}, SignalCountingWorkflow)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed starting workflow: %w\", err)\r\n\t}\r\n\r\n\tlog.Printf(\"Sending 500 signals\")\r\n\tfor i := 0; i < 500; i++ {\r\n\t\tif err := c.SignalWorkflow(ctx, run.GetID(), run.GetRunID(), \"my-signal\", \"some-arg\"); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed signalling workflow: %w\", err)\r\n\t\t}\r\n\t}\r\n\r\n\tlog.Printf(\"Waiting for query to show 500 signals received\")\r\n\tvar signalCount int\r\n\tfor start := time.Now(); signalCount != 500 && time.Since(start) < 10*time.Second; {\r\n\t\ttime.Sleep(50 * time.Millisecond)\r\n\t\tval, err := c.QueryWorkflow(ctx, run.GetID(), run.GetRunID(), \"get-signal-count\")\r\n\t\t// Ignore query failed because it means query may not be registered yet\r\n\t\tvar queryFailed *serviceerror.QueryFailed\r\n\t\tif errors.As(err, &queryFailed) {\r\n\t\t\tcontinue\r\n\t\t} else if err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed querying: %w\", err)\r\n\t\t} else if err := val.Get(&signalCount); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed decoding query: %w\", err)\r\n\t\t}\r\n\t}\r\n\tif signalCount != 500 {\r\n\t\treturn fmt.Errorf(\"expected signal count never reached\")\r\n\t}\r\n\r\n\tlog.Printf(\"Stopping worker\")\r\n\tworker1.Stop()\r\n\tworker1 = nil\r\n\r\n\tlog.Printf(\"Starting worker 2\")\r\n\t// Recreate client to capture metrics\r\n\ttestScope := tally.NewTestScope(\"\", nil)\r\n\tc, err = client.NewClient(client.Options{MetricsHandler: sdktally.NewMetricsHandler(testScope)})\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed creating client: %w\", err)\r\n\t}\r\n\tdefer c.Close()\r\n\tworker2 := worker.New(c, taskQueue, worker.Options{})\r\n\tworker2.RegisterWorkflow(SignalCountingWorkflow)\r\n\tif err := worker2.Start(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed starting worker client: %w\", err)\r\n\t}\r\n\tdefer worker2.Stop()\r\n\r\n\tlog.Printf(\"Performing several queries\")\r\n\tfor i := 0; i < 5; i++ {\r\n\t\tif _, err := c.QueryWorkflow(ctx, run.GetID(), run.GetRunID(), \"get-signal-count\"); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed querying: %w\", err)\r\n\t\t}\r\n\t\t// Get cache size metric\r\n\t\tvar cacheSize float64\r\n\t\tfor _, gauge := range testScope.Snapshot().Gauges() {\r\n\t\t\tif gauge.Name() == \"temporal_sticky_cache_size\" {\r\n\t\t\t\tcacheSize += gauge.Value()\r\n\t\t\t}\r\n\t\t}\r\n\t\tlog.Printf(\"Query #%v complete, cache size: %v\", i+1, cacheSize)\r\n\t}\r\n\treturn nil\r\n}\r\n\r\nfunc SignalCountingWorkflow(ctx workflow.Context) error {\r\n\tworkflow.GetLogger(ctx).Info(\"Starting workflow\")\r\n\tlog.Printf(\"Running workflow code (replaying? %v)\", workflow.IsReplaying(ctx))\r\n\tdefer workflow.GetLogger(ctx).Info(\"Completing workflow\")\r\n\tdefer func() { log.Printf(\"Finishing workflow code (replaying? %v)\", workflow.IsReplaying(ctx)) }()\r\n\r\n\tsignalCount := 0\r\n\terr := workflow.SetQueryHandler(ctx, \"get-signal-count\", func() (int, error) { return signalCount, nil })\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsignalCh := workflow.GetSignalChannel(ctx, \"my-signal\")\r\n\tfor {\r\n\t\tsignalCh.Receive(ctx, nil)\r\n\t\tsignalCount++\r\n\t}\r\n}\r\n```\r\n\r\n</details>\r\n\r\nRunning gives the following logs:\r\n\r\n```\r\n2022/04/13 10:19:11 Creating client\r\n2022/04/13 10:19:11 INFO  No logger configured for temporal client. Created default one.\r\n2022/04/13 10:19:11 Starting worker 1\r\n2022/04/13 10:19:11 INFO  Started Worker Namespace default TaskQueue 559865d2-9872-48ba-a8d7-12ba77360358 WorkerID 4190@cretz-laptop@\r\n2022/04/13 10:19:11 Starting workflow\r\n2022/04/13 10:19:11 Sending 500 signals\r\n2022/04/13 10:19:11 INFO  Starting workflow Namespace default TaskQueue 559865d2-9872-48ba-a8d7-12ba77360358 WorkerID 4190@cretz-laptop@ WorkflowType SignalCountingWorkflow WorkflowID 372aa87f-884a-476f-8276-a691bba62553 RunID 5136780a-cc02-47cc-ae90-37681413b0bc Attempt 1\r\n2022/04/13 10:19:11 Running workflow code (replaying? false)\r\n2022/04/13 10:19:15 Waiting for query to show 500 signals received\r\n2022/04/13 10:19:15 Stopping worker\r\n2022/04/13 10:19:15 WARN  Failed to poll for task. Namespace default TaskQueue 559865d2-9872-48ba-a8d7-12ba77360358 WorkerID 4190@cretz-laptop@ WorkerType WorkflowWorker Error worker stopping\r\n2022/04/13 10:19:15 WARN  Failed to poll for task. Namespace default TaskQueue 559865d2-9872-48ba-a8d7-12ba77360358 WorkerID 4190@cretz-laptop@ WorkerType ActivityWorker Error worker stopping\r\n2022/04/13 10:19:15 INFO  Stopped Worker Namespace default TaskQueue 559865d2-9872-48ba-a8d7-12ba77360358 WorkerID 4190@cretz-laptop@\r\n2022/04/13 10:19:15 Starting worker 2\r\n2022/04/13 10:19:15 INFO  No logger configured for temporal client. Created default one.\r\n2022/04/13 10:19:15 INFO  Started Worker Namespace default TaskQueue 559865d2-9872-48ba-a8d7-12ba77360358 WorkerID 4190@cretz-laptop@\r\n2022/04/13 10:19:15 Performing several queries\r\n2022/04/13 10:19:20 Running workflow code (replaying? true)\r\n2022/04/13 10:19:20 Query #1 complete, cache size: 1\r\n2022/04/13 10:19:20 Running workflow code (replaying? true)\r\n2022/04/13 10:19:20 Query #2 complete, cache size: 1\r\n2022/04/13 10:19:20 Running workflow code (replaying? true)\r\n2022/04/13 10:19:20 Query #3 complete, cache size: 1\r\n2022/04/13 10:19:20 Running workflow code (replaying? true)\r\n2022/04/13 10:19:20 Query #4 complete, cache size: 1\r\n2022/04/13 10:19:20 Running workflow code (replaying? true)\r\n2022/04/13 10:19:20 Query #5 complete, cache size: 1\r\n2022/04/13 10:19:20 INFO  Stopped Worker Namespace default TaskQueue 559865d2-9872-48ba-a8d7-12ba77360358 WorkerID 4190@cretz-laptop@\r\n2022/04/13 10:19:20 WARN  Failed to poll for task. Namespace default TaskQueue 559865d2-9872-48ba-a8d7-12ba77360358 WorkerID 4190@cretz-laptop@ WorkerType WorkflowWorker Error worker stopping\r\n```\r\n\r\nThere is a lull sending the signals and a bit of a lull stopping the worker due to sticky cache being enabled by default. But this shows that the cache size is not growing and that \"Starting workflow\" log not happening on each query. Can you confirm and/or make changes to the standalone replication code to replicate what you are seeing?","createdAt":"2022-04-13T15:23:41Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-go/issues/774#issuecomment-1098186495","viewerDidAuthor":false},{"id":"IC_kwDODN1w685BdvKc","author":{"login":""},"authorAssociation":"NONE","body":"@cretz thanks for watching this. \r\n\r\nYou're right about the logs, I ended up replacing the log by simple printing to the console.\r\n\r\nWhen executing only queries, you can see the \"workflow start\" in the console for every call and never the defer message, which it seems to me that another instance was allocated and replayed from scratch. \r\n\r\nIf the first call to the workflow is a signal, you can see the  \"workflow start\" just once, and for all following query calls, the cache is reused.\r\n\r\nIn the first scenario, if you make only queries, you can notice how the memory is increased and never released. Maybe is not a memory leak per-se, but it seems that for the same workflow the listener or so is being allocated multiple times.\r\n\r\nI have seen this behavior only after the Worker starts and until the workflow receives the first signal. ","createdAt":"2022-04-13T17:37:40Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-go/issues/774#issuecomment-1098314396","viewerDidAuthor":false},{"id":"IC_kwDODN1w685Bd5oy","author":{"login":""},"authorAssociation":"NONE","body":"I modified a bit your test to show you what I'm seeing\r\n\r\n<details>\r\n  <summary>main.go</summary>\r\n\r\n```go\r\n\r\npackage main\r\n\r\nimport (\r\n\t\"context\"\r\n\t\"errors\"\r\n\t\"fmt\"\r\n\t\"log\"\r\n\t\"runtime\"\r\n\t\"time\"\r\n\r\n\t\"github.com/google/uuid\"\r\n\t\"github.com/uber-go/tally/v4\"\r\n\t\"go.temporal.io/api/serviceerror\"\r\n\t\"go.temporal.io/sdk/client\"\r\n\tsdktally \"go.temporal.io/sdk/contrib/tally\"\r\n\t\"go.temporal.io/sdk/worker\"\r\n\t\"go.temporal.io/sdk/workflow\"\r\n)\r\n\r\nfunc main() {\r\n\tif err := run(); err != nil {\r\n\t\tlog.Fatal(err)\r\n\t}\r\n}\r\n\r\nfunc run() error {\r\n\tctx, cancel := context.WithCancel(context.Background())\r\n\tdefer cancel()\r\n\r\n\tlog.Printf(\"Creating client\")\r\n\tc, err := client.NewClient(client.Options{})\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed creating client: %w\", err)\r\n\t}\r\n\tdefer c.Close()\r\n\r\n\tlog.Printf(\"Starting worker 1\")\r\n\ttaskQueue := uuid.NewString()\r\n\tworker1 := worker.New(c, taskQueue, worker.Options{})\r\n\tworker1.RegisterWorkflow(SignalCountingWorkflow)\r\n\tif err := worker1.Start(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed starting worker client: %w\", err)\r\n\t}\r\n\tdefer func() {\r\n\t\tif worker1 != nil {\r\n\t\t\tworker1.Stop()\r\n\t\t}\r\n\t}()\r\n\r\n\tlog.Printf(\"Starting workflow\")\r\n\trun, err := c.ExecuteWorkflow(ctx, client.StartWorkflowOptions{TaskQueue: taskQueue}, SignalCountingWorkflow)\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed starting workflow: %w\", err)\r\n\t}\r\n\r\n\tlog.Printf(\"Sending 500 signals\")\r\n\tfor i := 0; i < 500; i++ {\r\n\t\tif err := c.SignalWorkflow(ctx, run.GetID(), \"\", \"my-signal\", \"some-arg\"); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed signalling workflow: %w\", err)\r\n\t\t}\r\n\t}\r\n\r\n\tlog.Printf(\"Waiting for query to show 500 signals received\")\r\n\tvar signalCount int\r\n\tfor start := time.Now(); signalCount != 500 && time.Since(start) < 10*time.Second; {\r\n\t\ttime.Sleep(50 * time.Millisecond)\r\n\t\tval, err := c.QueryWorkflow(ctx, run.GetID(), \"\", \"get-signal-count\")\r\n\t\t// Ignore query failed because it means query may not be registered yet\r\n\t\tvar queryFailed *serviceerror.QueryFailed\r\n\t\tif errors.As(err, &queryFailed) {\r\n\t\t\tcontinue\r\n\t\t} else if err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed querying: %w\", err)\r\n\t\t} else if err := val.Get(&signalCount); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed decoding query: %w\", err)\r\n\t\t}\r\n\t}\r\n\tif signalCount != 500 {\r\n\t\treturn fmt.Errorf(\"expected signal count never reached\")\r\n\t}\r\n\r\n\tlog.Printf(\"Stopping worker\")\r\n\tworker1.Stop()\r\n\tworker1 = nil\r\n\r\n\tlog.Printf(\"Starting worker 2\")\r\n\t// Recreate client to capture metrics\r\n\ttestScope := tally.NewTestScope(\"\", nil)\r\n\tc, err = client.NewClient(client.Options{MetricsHandler: sdktally.NewMetricsHandler(testScope)})\r\n\tif err != nil {\r\n\t\treturn fmt.Errorf(\"failed creating client: %w\", err)\r\n\t}\r\n\tdefer c.Close()\r\n\tworker2 := worker.New(c, taskQueue, worker.Options{})\r\n\tworker2.RegisterWorkflow(SignalCountingWorkflow)\r\n\tif err := worker2.Start(); err != nil {\r\n\t\treturn fmt.Errorf(\"failed starting worker client: %w\", err)\r\n\t}\r\n\tdefer worker2.Stop()\r\n\r\n\tlog.Printf(\"Performing several queries\")\r\n\tlog.Printf(\"before querying\")\r\n\tprintMemoryUsage()\r\n\t// Test 1st with the following line commented, and then uncomment it and test again\r\n\t// Check the memory usage\r\n\t//\r\n\t// _ = c.SignalWorkflow(ctx, run.GetID(), \"\", \"my-signal\", \"some-arg\")\r\n\tfor i := 0; i < 500; i++ {\r\n\t\tprintMemoryUsage()\r\n\t\tif _, err := c.QueryWorkflow(ctx, run.GetID(), \"\", \"get-signal-count\"); err != nil {\r\n\t\t\treturn fmt.Errorf(\"failed querying: %w\", err)\r\n\t\t}\r\n\t\t// Get cache size metric\r\n\t\tvar cacheSize float64\r\n\t\tfor _, gauge := range testScope.Snapshot().Gauges() {\r\n\t\t\tif gauge.Name() == \"temporal_sticky_cache_size\" {\r\n\t\t\t\tcacheSize += gauge.Value()\r\n\t\t\t}\r\n\t\t}\r\n\t\tlog.Printf(\"Query #%v complete, cache size: %v\", i+1, cacheSize)\r\n\t}\r\n\treturn nil\r\n}\r\n\r\nfunc printMemoryUsage() {\r\n\tvar m runtime.MemStats\r\n\truntime.ReadMemStats(&m)\r\n\tfmt.Printf(\"Alloc = %v MiB\", bToMb(m.Alloc))\r\n\tfmt.Printf(\"\\tTotalAlloc = %v MiB\", bToMb(m.TotalAlloc))\r\n\tfmt.Printf(\"\\tSys = %v MiB\", bToMb(m.Sys))\r\n\tfmt.Printf(\"\\tNumGC = %v\\n\", m.NumGC)\r\n}\r\n\r\nfunc SignalCountingWorkflow(ctx workflow.Context) error {\r\n\tlog.Printf(\"Workflow starts\")\r\n\tdefer log.Printf(\"Workflow Exit\")\r\n\tworkflow.GetLogger(ctx).Info(\"Starting workflow\")\r\n\tlog.Printf(\"Running workflow code (replaying? %v)\", workflow.IsReplaying(ctx))\r\n\tdefer workflow.GetLogger(ctx).Info(\"Completing workflow\")\r\n\tdefer func() { log.Printf(\"Finishing workflow code (replaying? %v)\", workflow.IsReplaying(ctx)) }()\r\n\r\n\tsignalCount := 0\r\n\terr := workflow.SetQueryHandler(ctx, \"get-signal-count\", func() (int, error) { return signalCount, nil })\r\n\tif err != nil {\r\n\t\treturn err\r\n\t}\r\n\tsignalCh := workflow.GetSignalChannel(ctx, \"my-signal\")\r\n\tfor {\r\n\t\tsignalCh.Receive(ctx, nil)\r\n\t\tsignalCount++\r\n\t}\r\n}\r\n\r\nfunc bToMb(b uint64) uint64 {\r\n\treturn b / 1024 / 1024\r\n}\r\n\r\n```\r\n\r\n</details>\r\n\r\nI commented the line 107, pls test it first with that line commented and then uncomment it and test again\r\n\r\n```go\r\n\t// _ = c.SignalWorkflow(ctx, run.GetID(), \"\", \"my-signal\", \"some-arg\")\r\n```\r\n\r\nWith the line commented, you should see that after executing the last query the memory usage is like \r\n\r\n```\r\nAlloc = 12 MiB  TotalAlloc = 1776 MiB   Sys = 35 MiB    NumGC = 314\r\n```\r\nYou can also check the complete log to see how it is increased with every query.\r\n\r\nWith the line uncommented, you should see something like\r\n\r\n```\r\nAlloc = 4 MiB   TotalAlloc = 51 MiB     Sys = 19 MiB    NumGC = 23\r\n```\r\n\r\nThe second test I think shows what I'm seeing, after a signal the cache is set, and from there the queries reuse it.\r\n\r\nAlso notice that executing the same 500 queries is faster.\r\n\r\nHope this helps.\r\n","createdAt":"2022-04-13T18:28:49Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-go/issues/774#issuecomment-1098357298","viewerDidAuthor":false},{"id":"IC_kwDODN1w685Bd7xP","author":{"login":"cretz"},"authorAssociation":"MEMBER","body":"Thanks! I will check and confirm whether we cache query-only tasks. It is quite possible that we do not because it is possible to query completed workflows and we have intentionally chosen not to fill the cache for just queries which don't actually affect workflow execution. This only becomes obvious on large history size.\r\n\r\nI will do some investigation and confirm and see what options we have here.","createdAt":"2022-04-13T18:39:15Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-go/issues/774#issuecomment-1098366031","viewerDidAuthor":false},{"id":"IC_kwDODN1w685BhPp-","author":{"login":"cretz"},"authorAssociation":"MEMBER","body":"I have confirmed that the code intentionally does this. At https://github.com/temporalio/sdk-go/blob/706516c7077ba2e9b40304aeddbed47e25b2a68f/internal/internal_task_handlers.go#L636-L638 it intentionally does not cache tasks containing that query field (which means it's a query-only task). Also at https://github.com/temporalio/sdk-go/blob/706516c7077ba2e9b40304aeddbed47e25b2a68f/internal/internal_task_handlers.go#L606-L608 it will attempt to reuse a cached workflow if the query is present without the full history (which means the history is partial because we've cached it previously like when signal was run).\r\n\r\nOn query-only tasks we are not wanting to cache because they have no side effects. Since it's a side effect free process, it has traditionally been seen as a stateless/no-cache process. There is no advancement of workflow history/code. If this is problematic for your use cases, we can talk about potential options here to maybe expose more cache control over query-only situations.\r\n\r\nKnowing that this is intentional behavior, the concern now is memory leak. Sure not using the cache requires all workflow steps rerun each time making queries slower and temporarily causing more mem and gc cycles. But I am showing that the memory is constantly rising with each query. I am profiling that now.","createdAt":"2022-04-14T14:16:56Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-go/issues/774#issuecomment-1099233918","viewerDidAuthor":false},{"id":"IC_kwDODN1w685BicPL","author":{"login":"cretz"},"authorAssociation":"MEMBER","body":"I have opened a PR at #779 to fix the goroutine/mem leak that is occurring from queries over and over. If you add this to your `go.mod`:\r\n\r\n    replace go.temporal.io/sdk => github.com/cretz/temporal-sdk-go query-goroutine-leak\r\n\r\nAnd then run `go mod tidy` to turn that into a proper pseudo-version and then run the code again, you will see the memory usage now does not grow on repeated query invocations.\r\n\r\nAs for whether query-only workflow tasks should reuse a cache or not, that's a bit of a larger question and if there's a good enough use case we can look into make that opt-in.","createdAt":"2022-04-14T19:20:28Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-go/issues/774#issuecomment-1099547595","viewerDidAuthor":false},{"id":"IC_kwDODN1w685BqRNN","author":{"login":""},"authorAssociation":"NONE","body":"@cretz Awesome, thanks a lot.","createdAt":"2022-04-18T17:43:14Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":1}}],"url":"https://github.com/temporalio/sdk-go/issues/774#issuecomment-1101599565","viewerDidAuthor":false},{"id":"IC_kwDODN1w685CLfF6","author":{"login":"cretz"},"authorAssociation":"MEMBER","body":"This has been merged and should be released in a couple weeks. There should not be a leak anymore in this use case. I am closing the issue, but feel free to comment/reopen if it persists.\r\n\r\nIf the need to reuse a cache for query-only tasks is really necessary, which I am not sure it is, we can discuss in Slack or a new issue.","createdAt":"2022-04-26T22:21:17Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-go/issues/774#issuecomment-1110307194","viewerDidAuthor":false}],"createdAt":"2022-04-12T17:40:21Z","labels":[{"id":"MDU6TGFiZWwyMDUzODEzNTY0","name":"potential-bug","description":"","color":"90c109"}],"milestone":null,"number":774,"reactionGroups":[],"state":"CLOSED","title":"Possible memory leak when loading a workflow with a query","updatedAt":"2022-04-26T22:21:17Z","url":"https://github.com/temporalio/sdk-go/issues/774"}
