{"assignees":[],"author":{"id":"MDQ6VXNlcjY0MTIxNjk=","is_bot":false,"login":"mjameswh","name":"James Watkins-Harvey"},"body":"### Describe the bug\r\n\r\nTwo slack users reported seeing Worker crashes at shutdown time (after reaching the 'STOPPED' state), with the following error message:\r\n\r\n```\r\nRangeError: Maximum call stack size exceeded\r\n    at OperatorSubscriber.<anonymous> (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/util/lift.ts:26:16)\r\n    at <appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/Observable.ts:226:22\r\n    at Object.errorContext (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/util/errorContext.ts:29:5)\r\n    at Observable.subscribe (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/Observable.ts:220:5)\r\n    at subscribeToSource (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/operators/repeat.ts:151:30)\r\n    at resubscribe (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/operators/repeat.ts:145:13)\r\n    at subscribeToSource (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/operators/repeat.ts:166:13)\r\n( ... 6438 lines removed, jumping between repeat.ts:166:13 and repeat.ts:145:13 )\r\n    at resubscribe (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/operators/repeat.ts:145:13)\r\n    at <appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/operators/repeat.ts:155:19\r\n    at OperatorSubscriber._this._complete (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/operators/OperatorSubscriber.ts:92:13)\r\n    at OperatorSubscriber.Subscriber.complete (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/Subscriber.ts:106:12)\r\n    at checkComplete (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/operators/mergeInternals.ts:48:18)\r\n    at OperatorSubscriber.onFinalize (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/operators/mergeInternals.ts:125:15)\r\n    at OperatorSubscriber.unsubscribe (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/operators/OperatorSubscriber.ts:109:33)\r\n    at OperatorSubscriber._this._complete (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/operators/OperatorSubscriber.ts:98:18)\r\n    at OperatorSubscriber.Subscriber.complete (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/Subscriber.ts:106:12)\r\n    at OperatorSubscriber.Subscriber._complete (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/Subscriber.ts:132:24)\r\n    at OperatorSubscriber.Subscriber.complete (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/Subscriber.ts:106:12)\r\n    at <appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/operators/take.ts:65:28\r\n    at OperatorSubscriber._this._next (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/operators/OperatorSubscriber.ts:70:13)\r\n    at OperatorSubscriber.Subscriber.next (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/Subscriber.ts:75:12)\r\n    at AsyncAction.<anonymous> (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/observable/timer.ts:173:20)\r\n    at AsyncAction._execute (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/scheduler/AsyncAction.ts:120:12)\r\n    at AsyncAction.execute (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/scheduler/AsyncAction.ts:95:24)\r\n    at AsyncScheduler.flush (<appFolder>/node_modules/@temporalio/worker/node_modules/rxjs/src/internal/scheduler/AsyncScheduler.ts:40:27)\r\n    at listOnTimeout (node:internal/timers:564:17)\r\n    at processTimers (node:internal/timers:507:7)\r\n```\r\n\r\nThis only happens if using log forwarding:\r\n\r\n```\r\nRuntime.install({ \r\n  telemetryOptions: { logging: { forward: { level: 'INFO' } } },\r\n  // ... other options\r\n});\r\n```\r\n\r\nNo error is thrown if logging options are changed to the following:\r\n\r\n```\r\nRuntime.install({ \r\n  telemetryOptions: { logging: { filter: makeTelemetryFilterString({ core: 'INFO', other: 'INFO' }) } },\r\n  // ... other options\r\n});\r\n```","closedAt":"2023-09-12T17:10:27Z","comments":[{"id":"IC_kwDOEujx185k883E","author":{"login":"bergundy"},"authorAssociation":"MEMBER","body":"Note that I attempted to fix this and reverted it here: https://github.com/temporalio/sdk-typescript/pull/1152/commits/5b1f83dfa936e3c75baa3625a810daf5aef86a21.\r\n\r\nIt caused a memory leak, probably due to TS being unable to keep up with the rate of log emission.","createdAt":"2023-08-25T17:24:21Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-typescript/issues/1224#issuecomment-1693699524","viewerDidAuthor":false},{"id":"IC_kwDOEujx185k960-","author":{"login":"mjameswh"},"authorAssociation":"MEMBER","body":"> Note that I attempted to fix this and reverted it here.\r\n\r\nOh, really? That's exactly what I had in mind a little bit earlier.\r\n\r\n> It caused a memory leak, probably due to TS being unable to keep up with the rate of log emission.\r\n\r\nThat's strange... Why would rxjs be able to keep up, but pure TS code wouldn't? rxjs isn't magically making nodejs faster.\r\n\r\nCan you give some details on what you mean exactly by memory leak here? I suppose that wouldn't be on rust side, as the message buffer gets emptied every time we poll from it. Was it simply that you went out of heap at some point, or were you observing a progressive increase in heap usage?\r\n\r\nI get the feeling that this might be due to the fact that, in the refactored code, the `logs` array is being retained a bit too long (ie. it remains in scope while we sleep) and that's making it difficult for GC to collect back that memory. If that's the case, simply moving the \"poll and process log entries\" part out to a different function would fix it.","createdAt":"2023-08-25T21:25:58Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-typescript/issues/1224#issuecomment-1693953342","viewerDidAuthor":false},{"id":"IC_kwDOEujx185k9_6r","author":{"login":"mjameswh"},"authorAssociation":"MEMBER","body":"I restored your original attempt (as is) [here](https://github.com/temporalio/sdk-typescript/pull/1225).","createdAt":"2023-08-25T21:54:21Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-typescript/issues/1224#issuecomment-1693974187","viewerDidAuthor":false}],"createdAt":"2023-08-25T17:20:15Z","labels":[{"id":"MDU6TGFiZWwyNTQ1Mzg0MDA2","name":"bug","description":"Something isn't working","color":"d73a4a"}],"milestone":null,"number":1224,"reactionGroups":[],"state":"CLOSED","title":"[Bug] `RangeError: Maximum call stack size exceeded` on Worker shutdown","updatedAt":"2023-09-12T17:10:27Z","url":"https://github.com/temporalio/sdk-typescript/issues/1224"}
