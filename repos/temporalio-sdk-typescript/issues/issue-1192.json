{"assignees":[],"author":{"id":"MDQ6VXNlcjQyMjQyMDU1","is_bot":false,"login":"Naik1994","name":"Harish Naik B S"},"body":"### What are you really trying to do?\r\n\r\nWe are using the Temporal SDK in one of our microservices deployed on an ECS container with a Linux OS. During load testing, we observed that the memory utilization gradually increased up to 50%, including heap memory, and it did not decrease until the server was restarted or stopped. Further investigation revealed that running the same codebase on a local system with Windows OS exhibited no issues. The heap memory was released promptly after 10 to 15 minutes. However, this behavior was not replicated when running the application on AWS environment.\r\n\r\nHowever after passing the maxCachedWorkflows option as zero while creating the worker, the workflows are no longer being cached by the worker, and this has resolved the memory utilization issue. As a result, the heap memory is now getting released properly, and the problem is resolved temporarily as of now.\r\n\r\nRequest you to check and let us know if we need to do any specific configuration for container application to resolve above issue without passing **maxCachedWorkflows** option to worker.\r\n\r\nawait Worker.create({\r\n    workflowsPath: require.resolve('./workflow'),\r\n    connection,\r\n    activities: createActivities(),\r\n    taskQueue: 'test-'+process.env.stage,\r\n    namespace: 'test',\r\n    sinks: defaultSinks(workflowLogger),\r\n    maxCachedWorkflows: 0\r\n  })\r\n\r\n### Describe the bug\r\n\r\nWe ran the hello world typescript sample shared by temporal on windows and observed that heap memory occupied while running activities got released automatically once the load gradually decreased on server.\r\n\r\n1] without passing maxCachedWorkflows attribute in the option ->\r\nnumCachedWorkflows value was 100 since we triggered our code 100 times and heap memory got released slowly after the load is gone also it got released further once worker was idle for some time period.\r\n\r\n![image](https://github.com/temporalio/sdk-typescript/assets/42242055/64ca0cd3-c332-40c4-aebe-67d5a2afb5d3)\r\n\r\n![image](https://github.com/temporalio/sdk-typescript/assets/42242055/42110313-402d-476d-a718-8088f91b1873)\r\n\r\n![image](https://github.com/temporalio/sdk-typescript/assets/42242055/594ea0b6-6dbc-4196-be65-4670f3771c27)\r\n\r\n\r\n2] by passing maxCachedWorkflows attribute in the option ->\r\n\r\nWorkflows were not getting cached i.e numCachedWorkflows value was mostly zero, hence memory got released immediately after load decreased gradually.\r\n\r\n![image](https://github.com/temporalio/sdk-typescript/assets/42242055/2657ceaa-c9c2-4182-8ada-33d125f6bf5a)\r\n\r\n\r\n### Environment/Versions\r\n\r\n<!-- Please complete the following information where relevant. -->\r\n\r\nBelow is the configuration we are using for our own application.\r\n- OS and processor: [Linux]\r\n- SDK version: \r\n    \"@temporalio/activity\": \"^1.7.4\",\r\n    \"@temporalio/client\": \"^1.7.4\",\r\n    \"@temporalio/worker\": \"^1.7.4\",\r\n    \"@temporalio/workflow\": \"^1.7.4\"\r\n- We have deployed our containerized application on AWS ECS with Node image 16.4.1\r\n\r\n","closedAt":"2023-08-04T20:31:02Z","comments":[{"id":"IC_kwDOEujx185jMHqx","author":{"login":"mjameswh"},"authorAssociation":"MEMBER","body":"I don't understand what is incorrect in your description. Seems like what you describe matches the expected behavior.\r\n\r\nThe `maxCachedWorkflows` setting control how many workflow executions are retained in local memory, so that further events affecting those workflow can be executed more efficiently. By definition, that means that increasing `maxCachedWorkflows` will increase memory usage.\r\n\r\nAlso note that Node JS heap is managed by a garbage collector. That means that objects in heap memory may not get immediately released. It's therefore expected that memory usage may take some time to go down after the completion of your workflows.\r\n\r\nHere's something you can try: what happen if you steadily execute workflows for a long period of time. Does memory usage continue to grow, or does it stabilize at some point?","createdAt":"2023-08-03T14:42:31Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-typescript/issues/1192#issuecomment-1664121521","viewerDidAuthor":false},{"id":"IC_kwDOEujx185jMVZE","author":{"login":"Naik1994"},"authorAssociation":"NONE","body":"We are not using the maxCachedWorkflows setting by default. Initially, we deployed our application without it, but then we observed that memory utilization increased during load testing. We monitored the system for 2-3 days after the load test, but the memory consumed during that period was not being released.\r\n\r\nTo address the memory issue, we decided to use the maxCachedWorkflows setting and set it to zero. After this change, we noticed that the occupied memory was getting released within 10-15 minutes after the load test. However, as a trade-off, we also observed an increase in CPU consumption.\r\n\r\nBelow are the graph screenshots for your reference, which we tested over the last week.\r\n1] When tested without using the maxCachedWorkflows setting, the average memory utilization was around 34% for a couple of days. However, it decreased once we restarted the server.\r\n\r\n![image](https://github.com/temporalio/sdk-typescript/assets/42242055/5d6e6d0e-924f-40a5-a3a1-18d44dbdd3ad)\r\n\r\n2] When we tested using the maxCachedWorkflows setting set to 0, memory utilization was indeed released within 10-15 minutes after the load test. However, we observed that the average CPU utilization went above 100%, indicating a significant increase in CPU usage.\r\n\r\n![image](https://github.com/temporalio/sdk-typescript/assets/42242055/3c781890-d7dc-455f-8566-b4a2bb6c0083)\r\n\r\nHowever, in scenario 1, the application is functioning well on a local machine with Windows OS, and the heap memory is getting released as expected, even with cached workflows (please refer to the screenshots shared in the first thread). \r\n\r\nPlease check and let us know if we are missing any configurations or if this is the default behavior. Even if it is the expected behavior, I'm concerned that at some point we will experience 100% memory utilization, which could crash the application, as the memory utilization has stabilized at a higher rate.","createdAt":"2023-08-03T15:16:55Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-typescript/issues/1192#issuecomment-1664177732","viewerDidAuthor":false},{"id":"IC_kwDOEujx185jNk7Q","author":{"login":"mjameswh"},"authorAssociation":"MEMBER","body":"First of all, I strongly recommend that you update your `@temporalio/*` dependencies to 1.8.2. The 1.8.0 release introduced several performance related improvements. I also recommend that you enable the `WorkerOptions.reuseV8Context` option on your Worker, as this greatly reduce both memory usage and CPU usage.\r\n\r\nIf unspecified, `maxCachedWorkflows` defaults to 250 wf per GB of heap memory (that is up to TS SDK 1.7.4; the exact formula changed in 1.8.0, see [here](https://github.com/mjameswh/sdk-typescript/blob/08958f03fa30555ae3511dcb555cb3b56fcbee9c/packages/worker/src/worker-options.ts#L299-L300) for details). This is generally appropriate for day-to-day development; we however recommend that you explicitly configure `maxCachedWorkflows` in production environment, based on your specific application needs. Correctly tuning this involves performance testing.\r\n\r\nExplicitly setting `maxCachedWorkflows` to 0 disable workflow caching. This can be very detrimental for the performance of both your workers and your Temporal cluster. That is definitely not something you want to do in production.\r\n\r\n> Initially, we deployed our application without it, but then we observed that memory utilization increased during load testing.\r\n\r\nThis is expected. The cache size will increase until it reaches `maxCachedWorkflows`. From that point on, least recently used workflows will get evicted, so that you never have more than `maxCachedWorkflows` workflows in heap. At that point, memory usage should stabilize.\r\n\r\n> We monitored the system for 2-3 days after the load test, but the memory consumed during that period was not being released. [...] However, in scenario 1, the application is functioning well on a local machine with Windows OS, and the heap memory is getting released as expected, even with cached workflows (please refer to the screenshots shared in the first thread).\r\n\r\nNote that in your Windows screenshots, in your first message, the number of cached workflows is _not_ going down, even after the system has been idle for some time. The cache remains steadily at 100 wfs, and yet actual memory usage comes down to ~70 MB. The workflow cache has an LRU semantic. I'm not saying that a memory leak is impossible, but as far as I can see, the metrics you expose are coherent with the expected behavior.\r\n\r\nWhy then is the memory usage not going down in ECS's memory usage graph when workflow caching is enabled, while it does on Windows or when workflow caching is disabled? I have several possible factors in mind that may contribute to this apparent incoherency, but essentially all of it comes down to the way generational garbage collection works, and the fact that Windows and Linux manage memory differently.\r\n\r\n>  I'm concerned that at some point we will experience 100% memory utilization, which could crash the application, as the memory utilization has stabilized at a higher rate.\r\n\r\nI understand your concern. Workflows are not the only contributor to your process' memory usage. Activities and various other things running in that process/container may also require memory. Avoiding out-of-memory situations require finding a proper balance between all of these, and configuring your WorkerOptions' accordingly.","createdAt":"2023-08-03T19:18:13Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-typescript/issues/1192#issuecomment-1664503504","viewerDidAuthor":false},{"id":"IC_kwDOEujx185jSBE7","author":{"login":"Naik1994"},"authorAssociation":"NONE","body":"@mjameswh thanks for the support. We did test by upgrading all temporalio sdk libraries to latest version and enabling `reuseV8Context`, setting `maxCachedWorkflows` to 300 (just to see the behavior) and observed CPU utilization is below 100% however memory utilization is at 25% but stabilized. Does that mean memory will be at 25% and increasing as in when new workflows being executed?\r\n\r\n![image](https://github.com/temporalio/sdk-typescript/assets/42242055/c281c026-deda-421c-9d7b-f164ff10a96d)\r\n\r\nFYI, without enabling above settings default value of `maxCachedWorkflows` on Linux OS on AWS was set to 158 and on windows OS of local machine was 914. Meanwhile we will try to modify configuration and check the behavior further.","createdAt":"2023-08-04T14:06:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-typescript/issues/1192#issuecomment-1665667387","viewerDidAuthor":false},{"id":"IC_kwDOEujx185jTD9u","author":{"login":"mjameswh"},"authorAssociation":"MEMBER","body":">  Does that mean memory will be at 25% and increasing as in when new workflows being executed?\r\n\r\nIf that 25% memory usage actually represents the state where your workflow cache is full, then yes, memory usage should indeed stay relatively stable (variations are to be expected). If however that 25% correspond to your workflow cache currently containing only 100 workflows, and you allow your cache to grow to 300 workflows, then memory usage will increase when you'll start more workflows, until the cache reaches its full capacity.\r\n\r\nTry running a few hundreds of workflows (I'd say at least twice the number you specified in `maxCachedWorkflows`). That will ensure that the cache reaches its full capacity. At that point, you be get a better view of how much memory your cache is really taking.\r\n\r\nNote that the memory footprint of a single cached workflow really depends on the workflow code and the libraries used by that workflow. That's why you really need to measure this with your actual workflow.","createdAt":"2023-08-04T17:16:24Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-typescript/issues/1192#issuecomment-1665941358","viewerDidAuthor":false},{"id":"IC_kwDOEujx185jT2I7","author":{"login":"mjameswh"},"authorAssociation":"MEMBER","body":"@Naik1994 I'm closing this ticket, as there is nothing to do on our side.\r\n\r\nFeel free to continue the discussion if you still need help. You may also get help through our [Slack community](https://t.mp/slack) or our [community forum](https://community.temporal.io/).","createdAt":"2023-08-04T20:31:02Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/sdk-typescript/issues/1192#issuecomment-1666146875","viewerDidAuthor":false}],"createdAt":"2023-08-03T05:51:38Z","labels":[],"milestone":null,"number":1192,"reactionGroups":[],"state":"CLOSED","title":"[Bug] @temporalio/worker-1.7.4: Memory occupied by worker not getting released on AWS ECS (OS: Linux)","updatedAt":"2023-08-04T20:31:03Z","url":"https://github.com/temporalio/sdk-typescript/issues/1192"}
