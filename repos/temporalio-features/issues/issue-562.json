{"assignees":[],"author":{"id":"MDQ6VXNlcjE1Njc0OTg=","is_bot":false,"login":"schickling","name":"Johannes Schickling"},"body":"Would be great if [Sessions](https://docs.temporal.io/docs/go/sessions) similar to the Go SDK were supported in TS as well.","closedAt":null,"comments":[{"id":"IC_kwDOGflYbs6UOjUV","author":{"login":"lorensr"},"authorAssociation":"CONTRIBUTOR","body":"Here's an alternative:\r\n\r\nhttps://github.com/temporalio/samples-typescript/tree/main/activities-sticky-queues\r\n\r\nIf anyone has a use case in which this doesn't work well, please post a comment, thanks!\r\n","createdAt":"2022-11-08T00:30:06Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/features/issues/562#issuecomment-2486842645","viewerDidAuthor":false},{"id":"IC_kwDOGflYbs6UOjUb","author":{"login":"bergundy"},"authorAssociation":"MEMBER","body":"Note that the main difference between sticky activities and sessions is concurrency control, max concurrent sessions vs to max concurrent activities per worker.","createdAt":"2022-11-08T01:06:18Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/features/issues/562#issuecomment-2486842651","viewerDidAuthor":false},{"id":"IC_kwDOGflYbs6UOjUk","author":{"login":"morgante"},"authorAssociation":"NONE","body":"I took a look at the sticky queue but it's not clear that it matches exactly what I need. In particular, I have two doubts/questions:\r\n\r\n1. I want the worker to be able to listen on multiple queues. The workflow should only be coupled to a particular worker *after* it has picked up the first task.\r\n2. If the worker crashes midway through execution, how do I ensure the next worker that spawns for that workflow will start over from the beginning?","createdAt":"2023-03-27T00:06:29Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/features/issues/562#issuecomment-2486842660","viewerDidAuthor":false},{"id":"IC_kwDOGflYbs6UOjUn","author":{"login":"bergundy"},"authorAssociation":"MEMBER","body":"Sorry for the late response.\r\n\r\n> 1. I want the worker to be able to listen on multiple queues. The workflow should only be coupled to a particular worker _after_ it has picked up the first task.\r\n\r\nA worker only listens on a single task queue but you can start multiple workers in the same process.\r\nCoupling the workflow to a worker is shown in the sample posted above.\r\n\r\n> 2. If the worker crashes midway through execution, how do I ensure the next worker that spawns for that workflow will start over from the beginning?\r\n\r\nYou'll need to use schedule to start timeout to detect that the worker went away and restart the sequence of activities.\r\nThis is all part of the sticky activity queues sample.","createdAt":"2023-04-13T00:38:13Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/features/issues/562#issuecomment-2486842663","viewerDidAuthor":false},{"id":"IC_kwDOGflYbs6UXc6s","author":{"login":"cretz"},"authorAssociation":"MEMBER","body":"This appears to have been transferred from the TypeScript SDK issue tracker, but for those wondering, all SDKs support a concept of \"worker-specific task queues\" which basically provides session behavior.","createdAt":"2024-11-20T17:28:23Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/features/issues/562#issuecomment-2489175724","viewerDidAuthor":false},{"id":"IC_kwDOGflYbs7WgqmA","author":{"login":"jinvillaz"},"authorAssociation":"NONE","body":"# Response: Worker-Specific Task Queue Pattern Implementation\n\nThank you for the detailed response and for tracking this in temporalio/features#562. I appreciate the context about the redesign requirements and the challenges with the current Go Sessions implementation. I'd like to share our architectural approach to the Worker-Specific Task Queue pattern, addressing the points you raised, as it might provide valuable insights for the Sessions redesign.\n\n## Our Architecture Overview\n\n### Two-Task-Queue Design\n\nWe operate with two separate task queues:\n\n1. **Schedule Task Queue** (`schedule-tq`): Dedicated exclusively for schedule workflows that trigger ETL workflows\n2. **ETL Task Queue** (`etl-process-worker-{N}`): Worker-specific queues for actual ETL workflow execution\n\nThis separation ensures that schedule triggers don't interfere with ETL execution, and each worker has its own dedicated queue for ETL workflows.\n\n### Sequential Execution Model\n\nOur ETL workflows are **sequential** by design - activities execute one after another, not in parallel. Therefore:\n- `maxConcurrentWorkflowTaskExecutions` = `maxConcurrentActivityTaskExecutions` = `maxCapacity`\n- All three values are set to the same number (e.g., 5)\n- This ensures that a worker handling 5 workflows can execute 5 workflow tasks and 5 activity tasks concurrently, which matches our sequential model\n\n**Key Point**: The critical mechanism for our use case is `maxCapacity` - this is what we use to distribute complete workflows across workers and prevent overloading any single worker.\n\n## Addressing Your Points\n\n### 1. \"It is possible to achieve almost the same behavior with the Worker Specific Task Queue pattern, but it is quite daring to properly implement by users\"\n\n**Our Architectural Approach:**\n\nWe've implemented a database-backed worker registration and load balancing system that addresses the \"daring\" aspects:\n\n**Worker Registration Layer:**\n- Each worker instance registers itself in PostgreSQL with a unique task queue identifier (e.g., `etl-process-worker-1`, `etl-process-worker-2`)\n- Registration includes: status (ACTIVE/INACTIVE), `maxCapacity` (concurrent workflows), running workflows list, and last heartbeat timestamp\n- Workers automatically register on startup and deregister on shutdown\n\n**Centralized Load Balancer:**\n- Before starting any workflow, a centralized service queries the database for available workers\n- Uses PostgreSQL advisory locks (`pg_advisory_xact_lock`) to ensure atomic worker selection and reservation\n- Implements least-loaded-first selection algorithm based on `maxCapacity`\n- Atomically reserves a workflow slot before workflow execution begins\n\n**Why This Architecture:**\nThe \"daring\" part is ensuring atomicity and preventing race conditions. By using database transactions with advisory locks, we ensure that:\n- Only one workflow can reserve a worker slot at a time\n- Worker capacity is checked and updated atomically\n- No double-assignment can occur even under concurrent load\n\n### 2. \"User-land implementations have limited ability for controlling execution concurrency at the worker level\"\n\n**Our Concurrency Control:**\n\nSince our workflows are sequential, we set:\n- `maxConcurrentWorkflowTaskExecutions` = `maxConcurrentActivityTaskExecutions` = `maxCapacity`\n\n**The Critical Mechanism: `maxCapacity`**\n\n`maxCapacity` is the key to our solution. It represents how many **complete workflows** a worker can handle simultaneously. This is what we use to:\n- **Distribute workflows evenly** across available workers before they start\n- **Prevent overloading** any single worker with too many workflows\n- **Balance load** by selecting the least-loaded worker (based on current workflow count vs. `maxCapacity`)\n\n**Why This Matters:**\nWithout application-level `maxCapacity` tracking, Temporal's native concurrency controls would still allow multiple workflows to be assigned to the same worker. Our database-backed `maxCapacity` ensures that:\n- Workflows are distributed intelligently before execution\n- No worker gets more workflows than it can handle\n- We have visibility into which workflows are running on which workers\n\n### 3. \"Things have significantly improved with Custom Slot Providers and Poller Behaviors\"\n\nWe haven't explored Custom Slot Providers and Poller Behaviors because they address a different concern than our use case. These features improve concurrency control and polling efficiency **within** a single worker instance, while our challenge is:\n\n- **Distributing workflows across multiple workers** before they start\n- **Ensuring workflow affinity** to a specific worker (all tasks execute on the same worker)\n- **Balancing load** at the workflow level across workers\n\nFor our specific use case (workflow-level distribution and affinity), our implementation using worker-specific task queues addresses these requirements effectively.\n\n### 4. \"The current design can't offer the kind of DX and operational guarantees that Temporal users expect, notably when it comes to error-handling scenarios\"\n\n**Error Handling Challenges We've Encountered:**\n\nOur implementation revealed several critical error-handling complexities:\n\n#### Challenge 1: Concurrent Schedule Triggers and Load Balancing\n\n**Problem**: When multiple schedules trigger simultaneously (e.g., multiple ETL schedules fire at the same time), we need to ensure:\n- Each workflow gets assigned to exactly one worker (1:1 assignment)\n- Load is balanced across workers\n- No race conditions occur where multiple workflows are assigned to the same worker slot\n\n**Our Solution - Two-Level Serialization:**\n\n1. **Application-Level Queue Lock**: We use a promise-based queue (`queueLock`) in the `WorkflowBalancerService` that serializes all worker reservation requests. This ensures that even if multiple schedule workflows call `startEtlWorkflow()` simultaneously, they are processed one at a time.\n\n2. **Database-Level Atomic Reservation**: Within each reservation attempt, we use PostgreSQL advisory locks (`pg_advisory_xact_lock`) combined with a database transaction to ensure atomicity:\n   - Lock is acquired\n   - Available workers are queried\n   - Least-loaded worker is selected\n   - Workflow is added to worker's `runningWorkflows` array\n   - Transaction commits (releasing lock)\n\n**Why Both Levels:**\n- Application-level queue prevents overwhelming the database with concurrent requests\n- Database-level lock ensures atomicity even if multiple services/instances try to reserve simultaneously\n- Together, they guarantee 1:1 assignment and proper load balancing\n\n#### Challenge 2: Tracking Workflow Completion and Cleanup\n\n**Problem**: When a workflow completes (successfully or with failure), we need to:\n- Remove it from the worker's `runningWorkflows` array\n- Free up the capacity slot for new workflows\n- Handle cases where workflows terminate unexpectedly\n\n**Our Solution - Periodic Cleanup:**\n\nEach worker runs a periodic cleanup process (every heartbeat interval, default 30 seconds) that:\n1. Queries Temporal API to check the status of all tracked workflows\n2. Removes workflows that are no longer RUNNING (completed, failed, terminated, or not found)\n3. Updates the database to free up capacity\n\n**Challenges:**\n- Cleanup runs on an interval, so there's a delay before capacity is freed up\n- Requires querying Temporal API for each tracked workflow, which can be expensive\n- Need to handle cases where Temporal API is temporarily unavailable\n\n#### Challenge 3: Worker Health Monitoring (Heartbeat)\n\n**Problem**: We need to detect when a worker dies or becomes unresponsive, so we can:\n- Mark it as INACTIVE\n- Prevent new workflows from being assigned to it\n- Clean up stale workflow assignments\n\n**Our Solution - Heartbeat Mechanism:**\n\n1. **Heartbeat Sending**: Each worker sends a heartbeat to the database every 30 seconds (configurable), updating its `lastHeartbeat` timestamp\n2. **Dead Worker Detection**: A cleanup process checks for workers whose `lastHeartbeat` is older than 2x the heartbeat interval (60 seconds default)\n3. **Worker Deactivation**: Dead workers are marked as INACTIVE\n4. **Stale Workflow Cleanup**: Workflows assigned to dead workers are removed from tracking\n\n**Challenges:**\n- There's a window (up to 60 seconds) where a dead worker might still be considered ACTIVE\n- Network issues might cause false positives (worker is alive but can't reach database)\n- Need to handle database unavailability gracefully\n\n## Use Case: File Download and Sequential Processing\n\n**Scenario**: Our ETL workflows download large files (often several GB) from vendor APIs and process them sequentially in chunks.\n\n**Workflow Pattern:**\n1. Download file once per workflow\n2. Read file in sequential chunks (chunk 1, then chunk 2, then chunk 3, etc.)\n3. Process each chunk with stateful operations\n4. Maintain file handles and state throughout the workflow\n\n**Why Sticky Execution is Critical:**\n- **File handles are tied to worker filesystem**: Once a file is downloaded on Worker A, subsequent chunk reads must happen on the same worker to access the local file handle\n- **State preservation**: Partial processing state (buffers, cursors, file positions) is maintained in memory on the worker\n- **Network efficiency**: Re-downloading the file for each activity defeats the purpose of chunked processing\n- **Resource management**: File system resources are tied to specific worker instances\n\n**How Our Architecture Addresses This:**\n- Workflow is assigned to a specific worker (via `maxCapacity`-based selection) **before** it starts\n- All workflow tasks execute on that worker's specific task queue\n- All activities execute on the same worker\n- File handles persist throughout workflow execution\n- State is maintained in worker memory throughout the workflow lifecycle\n\n## Architecture Components\n\n### 1. Worker Registration Service\n- Registers workers in database on startup with unique task queue name\n- Updates heartbeats periodically\n- Deregisters on shutdown\n- Manages worker lifecycle\n\n### 2. Heartbeat Service\n- Sends periodic heartbeats (configurable interval, default 30s)\n- Detects and marks dead workers as INACTIVE (no heartbeat for 2x interval)\n- Triggers cleanup of stale workflow assignments\n\n### 3. Workflow Balancer Service\n- **Application-level queue**: Serializes worker reservation requests to prevent concurrent conflicts\n- **Worker selection**: Queries database, filters by capacity, selects least-loaded worker\n- **Atomic reservation**: Uses PostgreSQL advisory locks to ensure 1:1 assignment\n- **Workflow execution**: Starts workflow on selected worker's specific task queue\n- **Status checking**: Verifies if workflow is already running before assignment\n\n### 4. Database Schema\n- Workers table: `task_queue` (unique), `status`, `max_capacity`, `running_workflows[]`, `last_heartbeat`\n- Provides single source of truth for worker state\n- Enables atomic operations with advisory locks\n\n### Data Flow\n\n```\nSchedule Workflow Triggers (Multiple Simultaneous)\n    ↓\nApplication-Level Queue (Serializes Requests)\n    ↓\nFor Each Request:\n    ↓\n    Check if Workflow Already Running\n    ↓\n    Database Query: Find Available Workers\n    ↓\n    PostgreSQL Advisory Lock Acquired\n    ↓\n    Filter by Capacity (runningWorkflows.length < maxCapacity)\n    ↓\n    Select Least-Loaded Worker\n    ↓\n    Atomically Reserve Slot (Add workflowId to runningWorkflows)\n    ↓\n    Lock Released\n    ↓\n    Start Workflow on Worker's Specific Task Queue\n    ↓\n    All Workflow Tasks Execute on That Worker\n    ↓\nPeriodic Cleanup:\n    ↓\n    Check Workflow Status via Temporal API\n    ↓\n    Remove Non-Running Workflows from Tracking\n    ↓\n    Free Up Capacity\n```\n\n## What We've Learned\n\n**What Works Well:**\n- Database-backed worker registration provides reliable state management\n- Two-level serialization (application queue + database locks) prevents race conditions\n- `maxCapacity`-based load balancing distributes workflows evenly\n- Heartbeat mechanism effectively detects dead workers\n- Atomic reservations guarantee 1:1 assignment\n\n**Pain Points:**\n- External database dependency adds operational complexity\n- Cleanup delays (30s interval) can temporarily block capacity\n- Requires querying the Temporal API for each tracked workflow during cleanup\n- Heartbeat window (60s) means dead workers might still receive assignments briefly\n- No native integration with Temporal's retry/timeout mechanisms\n- Limited observability compared to native Temporal features\n\nThank you for considering this feedback @mjameswh, and I look forward to contributing to the discussion.\n","createdAt":"2025-12-01T21:15:10Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/features/issues/562#issuecomment-3598887296","viewerDidAuthor":false}],"createdAt":"2021-11-15T17:44:24Z","labels":[{"id":"LA_kwDOGflYbs7XtLc6","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"milestone":null,"number":562,"reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":7}}],"state":"OPEN","title":"[Feature Request] Session support","updatedAt":"2025-12-01T21:15:10Z","url":"https://github.com/temporalio/features/issues/562"}
