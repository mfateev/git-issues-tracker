{"assignees":[],"author":{"id":"MDQ6VXNlcjQ0Njg3NDMz","is_bot":false,"login":"jmaeagle99","name":"Justin Anderson"},"body":"### Is your feature request related to a problem? Please describe.\n\nCurrently Temporal has limits on the max payload size that can be used for operations like starting a workflow or signaling a workflow. If a user hits this limit the request will fail, leaving the workflow run in a failed state. If a workflow can be updated to minimize the payload size (e.g. compress data, move to some other storage), existing workflow runs can be resumed.\n\n### Describe the solution you'd like\n\nIf the SDK knows the error limits for payloads, it can submit a workflow task failure rather than submitting a completion that contains oversized payloads. This saves network costs by avoiding the upload of known oversized payloads and allows workflows to continue, provided the workflow is updated to address the oversized payloads.\n\n### Additional context\n\n[<!-- Add any other context or screenshots about the feature request here. -->](https://docs.temporal.io/cloud/limits#transaction-payload-size-limit)\n\n### Per-SDK Tickets\n\n<!-- Add links here once the tickets are created (no need to create them immediately). -->\n\n- [ ] Go - \n- [ ] Java - \n- [ ] Core - \n- [ ] TypeScript - \n- [ ] .NET - \n- [ ] Ruby - \n- [ ] PHP - \n- [ ] Temporal CLI - \n","closedAt":null,"comments":[],"createdAt":"2026-01-20T20:01:03Z","labels":[{"id":"LA_kwDOGflYbs7XtLc6","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"milestone":null,"number":723,"reactionGroups":[],"state":"OPEN","title":"SDK should fail workflow task if payloads size it known to be too large","updatedAt":"2026-01-20T20:01:20Z","url":"https://github.com/temporalio/features/issues/723"}
