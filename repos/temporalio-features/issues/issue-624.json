{"assignees":[],"author":{"id":"MDQ6VXNlcjIwNjM5Ng==","is_bot":false,"login":"cretz","name":"Chad Retz"},"body":"### Describe the solution you'd like\n\nAlso see https://github.com/temporalio/sdk-go/issues/995. Basically this comes back as resource exhausted which is retried by gRPC client, and we should be failing the task.\n\nSo we should 1) create a new `WorkflowTaskFailedCause` for gRPC-message-too-large, and 2) update SDKs to capture the error in clients and convert to non-retryable failure, 3) when failing task because of this failure, clearly specify the enum. The SDK side needs a test confirming the behavior because identifying this error from the server is likely an ugly English-string-check conditional since it is embedded into gRPC server logic. Also, SDKs need to make sure to validate this against cloud which may return a different error due to network/proxy layers.\n\nThere is a general server issue open at https://github.com/temporalio/temporal/issues/7777 to make large tasks work, but that is unrelated to this graceful failure.\n\nEDIT: May need to review requirements above, it may be enough to just stop retrying in these situations\n\n### Per-SDK Tickets\n\n- [x] API - https://github.com/temporalio/api/pull/591\n- [x] Go - https://github.com/temporalio/sdk-go/issues/995\n- [x] Java - https://github.com/temporalio/sdk-java/issues/1585\n- [ ] Core\n    - https://github.com/temporalio/sdk-core/issues/462\n    - https://github.com/temporalio/sdk-core/issues/970\n- [x] TypeScript - N/A\n- [x] Python - N/A\n- [x] .NET - N/A\n- [x] Ruby - N/A\n- [x] PHP - N/A\n- [x] Temporal CLI - N/A","closedAt":null,"comments":[{"id":"IC_kwDOGflYbs6rsbhh","author":{"login":"cretz"},"authorAssociation":"MEMBER","body":"This was previously created at https://github.com/temporalio/features/issues/198 that I was unaware of when this was made, marking that one as duplicate of this one.","createdAt":"2025-05-14T14:53:31Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/features/issues/624#issuecomment-2880551009","viewerDidAuthor":false},{"id":"IC_kwDOGflYbs6rsoVu","author":{"login":"tsurdilo"},"authorAssociation":"MEMBER","body":"Would similar approach be good for InvalidArgument response from service when payload size limit is breached when for example scheduling activity / child workflow or doing continueAsNew, or is that already not being retried?","createdAt":"2025-05-14T15:08:22Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/features/issues/624#issuecomment-2880603502","viewerDidAuthor":false},{"id":"IC_kwDOGflYbs6rsyw5","author":{"login":"cretz"},"authorAssociation":"MEMBER","body":"Due to how gRPC enforces message size limits at the boundary (for good security reason) and how network devices may enforce it even further out from the frontend service, we do not have control over the server-side error when this happens nor can we customize it in modern gRPC Go. That's why it's all SDK side.","createdAt":"2025-05-14T15:20:57Z","includesCreatedEdit":true,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/features/issues/624#issuecomment-2880646201","viewerDidAuthor":false},{"id":"IC_kwDOGflYbs7Av0VM","author":{"login":"tsurdilo"},"authorAssociation":"MEMBER","body":"still a bit unclear about the expected behavior here. is sdk going to provide means to fail workflow execution on this error?\nmaybe we will still see workflow task failed event but sdk tells server not to retry the workflow task? just want to make sure fully understand what to look out for","createdAt":"2025-08-28T14:35:27Z","includesCreatedEdit":false,"isMinimized":false,"minimizedReason":"","reactionGroups":[],"url":"https://github.com/temporalio/features/issues/624#issuecomment-3233760588","viewerDidAuthor":false}],"createdAt":"2025-05-14T14:49:28Z","labels":[{"id":"LA_kwDOGflYbs7XtLc6","name":"enhancement","description":"New feature or request","color":"a2eeef"}],"milestone":null,"number":624,"reactionGroups":[{"content":"THUMBS_UP","users":{"totalCount":2}}],"state":"OPEN","title":"Gracefully fail gRPC-message-too-large issues in worker","updatedAt":"2025-08-28T14:35:28Z","url":"https://github.com/temporalio/features/issues/624"}
